{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRqT9nYFvnB2",
        "outputId": "7832f740-c0a7-4c9e-ff08-a836aec61552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-86643222.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df['seen_merchant_before'] = df.groupby('customer').apply(has_seen_merchant).explode().values.astype(int)\n",
            "/tmp/ipython-input-86643222.py:98: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df['cust_avg_tx_per_day_before'] = df.groupby('customer').apply(\n",
            "/tmp/ipython-input-86643222.py:139: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_encoded = df_encoded.replace({True: 1, False: 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Непрерывные признаки (11): ['age', 'amount', 'cust_total_tx', 'cust_unique_merch_total', 'cust_tx_before', 'cust_unique_merch_before', 'cust_max_tx_per_day', 'cust_avg_interval', 'cust_avg_tx_per_day_before', 'cust_tx_days_ratio', 'tx_last_7_days']\n",
            "Бинарные признаки (21): ['is_first_tx', 'seen_merchant_before', \"gender_'E'\", \"gender_'F'\", \"gender_'M'\", \"gender_'U'\", \"category_'es_barsandrestaurants'\", \"category_'es_contents'\", \"category_'es_fashion'\", \"category_'es_food'\"]...\n",
            "\n",
            "Данные после стандартизации:\n",
            "        age    amount  cust_total_tx  cust_unique_merch_total  cust_tx_before  \\\n",
            "0  1.504337  0.951321      -0.918952                 0.865256       -1.617505   \n",
            "1  1.504337 -0.190302      -0.918952                 0.865256       -1.596803   \n",
            "2  1.504337  0.164178      -0.918952                 0.865256       -1.576101   \n",
            "3  1.504337 -0.207806      -0.918952                 0.865256       -1.555400   \n",
            "4  1.504337  0.085544      -0.918952                 0.865256       -1.534698   \n",
            "\n",
            "   cust_unique_merch_before  cust_max_tx_per_day  cust_avg_interval  \\\n",
            "0                 -1.951470            -0.369985          -0.089158   \n",
            "1                 -1.690317            -0.369985          -0.089158   \n",
            "2                 -1.429164            -0.369985          -0.089158   \n",
            "3                 -1.429164            -0.369985          -0.089158   \n",
            "4                 -1.168011            -0.369985          -0.089158   \n",
            "\n",
            "   cust_avg_tx_per_day_before  cust_tx_days_ratio  ...  category_'es_home'  \\\n",
            "0                   -3.872895           -0.838601  ...                   0   \n",
            "1                   -3.302954           -0.838601  ...                   0   \n",
            "2                   -3.112974           -0.838601  ...                   0   \n",
            "3                   -2.820696           -0.838601  ...                   0   \n",
            "4                   -2.570173           -0.838601  ...                   0   \n",
            "\n",
            "   category_'es_hotelservices'  category_'es_hyper'  category_'es_leisure'  \\\n",
            "0                            0                    0                      0   \n",
            "1                            0                    0                      0   \n",
            "2                            0                    0                      0   \n",
            "3                            0                    0                      0   \n",
            "4                            0                    0                      0   \n",
            "\n",
            "   category_'es_otherservices'  category_'es_sportsandtoys'  \\\n",
            "0                            1                            0   \n",
            "1                            0                            1   \n",
            "2                            1                            0   \n",
            "3                            0                            0   \n",
            "4                            0                            0   \n",
            "\n",
            "   category_'es_tech'  category_'es_transportation'  category_'es_travel'  \\\n",
            "0                   0                             0                     0   \n",
            "1                   0                             0                     0   \n",
            "2                   0                             0                     0   \n",
            "3                   1                             0                     0   \n",
            "4                   0                             1                     0   \n",
            "\n",
            "   category_'es_wellnessandbeauty'  \n",
            "0                                0  \n",
            "1                                0  \n",
            "2                                0  \n",
            "3                                0  \n",
            "4                                0  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "Диапазоны значений:\n",
            "Непрерывные:                                  min        max\n",
            "age                        -2.268275   2.258859\n",
            "amount                     -0.340118  74.433206\n",
            "cust_total_tx              -5.326753   3.768709\n",
            "cust_unique_merch_total    -3.106134   6.491391\n",
            "cust_tx_before             -1.617505   3.847707\n",
            "cust_unique_merch_before   -1.951470   6.144276\n",
            "cust_max_tx_per_day        -2.127370   4.902170\n",
            "cust_avg_interval          -0.821524  53.675920\n",
            "cust_avg_tx_per_day_before -3.872895  23.484279\n",
            "cust_tx_days_ratio         -5.288053   0.905584\n",
            "tx_last_7_days             -4.183715  10.991080\n",
            "Бинарные: 0 или 1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Настройка стиля графиков\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Чтение файла\n",
        "df = pd.read_csv('bs140513_032310.csv')\n",
        "\n",
        "labels=['zipcodeOri', 'zipMerchant']\n",
        "df=df.drop(labels, axis=1, inplace=False, errors='raise')\n",
        "\n",
        "\n",
        "\n",
        "# Убедимся, что данные отсортированы по времени (важно для \"до текущего дня\")\n",
        "df = df.sort_values(['customer', 'step']).reset_index(drop=True)\n",
        "\n",
        "# 1. Общее количество транзакций за всё время для клиента\n",
        "df['cust_total_tx'] = df.groupby('customer')['step'].transform('count')\n",
        "\n",
        "# 2. Количество уникальных мерчантов, с которыми клиент взаимодействовал (всё время)\n",
        "df['cust_unique_merch_total'] = df.groupby('customer')['merchant'].transform('nunique')\n",
        "\n",
        "# 3. Сколько транзакций у клиента до текущего дня (исключая текущую)\n",
        "# Для этого используем cumulative count - 1\n",
        "df['cust_tx_before'] = df.groupby('customer').cumcount()\n",
        "\n",
        "# 4. Сколько уникальных мерчантов у клиента до текущего дня\n",
        "# Нужно аккуратно: считаем уникальные merchant_id до текущей строки\n",
        "def count_unique_before(series):\n",
        "    # series — это merchant_id для одного клиента, отсортированный по day\n",
        "    seen = set()\n",
        "    result = []\n",
        "    for merch in series:\n",
        "        result.append(len(seen))\n",
        "        seen.add(merch)\n",
        "    return result\n",
        "\n",
        "df['cust_unique_merch_before'] = df.groupby('customer')['merchant'].transform(count_unique_before)\n",
        "\n",
        "# 5. Бинарный признак: первая ли это транзакция клиента?\n",
        "df['is_first_tx'] = (df['cust_tx_before'] == 0).astype(int)\n",
        "\n",
        "# 6. Взаимодействовал ли клиент с этим мерчантом раньше? (до текущей транзакции)\n",
        "def has_seen_merchant(group):\n",
        "    seen = set()\n",
        "    res = []\n",
        "    for merch in group['merchant']:\n",
        "        res.append(1 if merch in seen else 0)\n",
        "        seen.add(merch)\n",
        "    return res\n",
        "\n",
        "df['seen_merchant_before'] = df.groupby('customer').apply(has_seen_merchant).explode().values.astype(int)\n",
        "\n",
        "# 7. Доля дней с транзакциями (всё время)\n",
        "# Сначала посчитаем уникальные дни у клиента\n",
        "cust_unique_days = df.groupby('customer')['step'].nunique()\n",
        "df['cust_unique_days'] = df['customer'].map(cust_unique_days)\n",
        "df['cust_tx_days_ratio'] = df['cust_unique_days'] / 180.0  # 180 — общее число дней\n",
        "\n",
        "# 8. Максимальное число транзакций за один день (всё время)\n",
        "daily_counts = df.groupby(['customer', 'step']).size().reset_index(name='daily_tx')\n",
        "max_daily = daily_counts.groupby('customer')['daily_tx'].max()\n",
        "df['cust_max_tx_per_day'] = df['customer'].map(max_daily)\n",
        "\n",
        "# 9. Средний интервал между транзакциями (всё время)\n",
        "def avg_interval(days):\n",
        "    if len(days) <= 1:\n",
        "        return np.nan  # или 0, но лучше NaN\n",
        "    diffs = np.diff(sorted(days))\n",
        "    return diffs.mean()\n",
        "\n",
        "cust_avg_int = df.groupby('customer')['step'].apply(avg_interval)\n",
        "df['cust_avg_interval'] = df['customer'].map(cust_avg_int)\n",
        "\n",
        "# 10. Среднее число транзакций в день у клиента (до текущего дня)\n",
        "# = cust_tx_before / (текущий день - первый день активности + 1), но проще:\n",
        "# Будем считать как: (число транзакций до текущего дня) / (число дней от первой транзакции до текущего дня)\n",
        "def avg_tx_per_day_before(group):\n",
        "    days = group['step'].values\n",
        "    tx_counts = np.arange(len(days))  # 0, 1, 2, ..., n-1\n",
        "    first_day = days[0]\n",
        "    result = []\n",
        "    for i, day in enumerate(days):\n",
        "        if i == 0:\n",
        "            result.append(0.0)  # или np.nan\n",
        "        else:\n",
        "            span_days = day - first_day\n",
        "            if span_days == 0:\n",
        "                result.append(np.nan)\n",
        "            else:\n",
        "                result.append(tx_counts[i] / span_days)\n",
        "    return result\n",
        "\n",
        "df['cust_avg_tx_per_day_before'] = df.groupby('customer').apply(\n",
        "    lambda g: pd.Series(avg_tx_per_day_before(g), index=g.index)\n",
        ").values\n",
        "\n",
        "# 11. Количество транзакций за последние 7 дней (до текущего дня, не включая текущую)\n",
        "# Используем rolling window по day (но day — не обязательно последовательные индексы)\n",
        "# Поэтому делаем через цикл или merge с временным окном\n",
        "\n",
        "# Создадим вспомогательный датафрейм для rolling-подсчёта\n",
        "df_sorted = df.copy()\n",
        "df_sorted = df_sorted.sort_values(['customer', 'step'])\n",
        "\n",
        "# Инициализируем колонку\n",
        "df_sorted['tx_last_7_days'] = 0\n",
        "\n",
        "# Группируем по клиенту и считаем для каждой транзакции\n",
        "for cust_id, group in df_sorted.groupby('customer'):\n",
        "    days = group['step'].values\n",
        "    indices = group.index\n",
        "    counts = []\n",
        "    for i, current_day in enumerate(days):\n",
        "        # Считаем транзакции в диапазоне (current_day - 7, current_day)\n",
        "        start_day = current_day - 7\n",
        "        # Только предыдущие транзакции (строго < current_day)\n",
        "        count = np.sum((days[:i] > start_day) & (days[:i] < current_day))\n",
        "        counts.append(count)\n",
        "    df_sorted.loc[indices, 'tx_last_7_days'] = counts\n",
        "\n",
        "# Вернём результат в исходный порядок (если был)\n",
        "df = df_sorted.sort_index().reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# Обработка категориальных признаков\n",
        "labels = ['step', 'customer', 'merchant']\n",
        "df = df.drop(labels, axis=1, inplace=False, errors='raise')\n",
        "\n",
        "# Применяем one-hot encoding к столбцам 'gender' и 'category'\n",
        "df_encoded = pd.get_dummies(df, columns=['gender', 'category'], prefix=['gender', 'category'])\n",
        "\n",
        "# Теперь преобразуем булевы значения в 0/1 и очищаем age сразу после создания df_encoded\n",
        "df_encoded = df_encoded.replace({True: 1, False: 0})\n",
        "df_encoded['age'] = pd.to_numeric(df_encoded['age'].str.replace(\"'\", \"\"), errors='coerce')\n",
        "\n",
        "# Теперь df_encoded содержит исходные столбцы (кроме 'gender' и 'category')\n",
        "# и новые бинарные столбцы вида gender_M, gender_F, category_food, category_travel и т.д.\n",
        "\n",
        "# print(df_encoded.head())\n",
        "# print(\"\\nСтолбцы после обработки:\")\n",
        "# print(df_encoded.columns)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
        "from scipy.cluster import hierarchy\n",
        "import scipy.cluster.hierarchy\n",
        "import scipy.spatial.distance\n",
        "%matplotlib inline\n",
        "\n",
        "# Сохраняем fraud отдельно для будущего анализа\n",
        "fraud_labels = df_encoded['fraud']  # сохраняем целевую переменную\n",
        "\n",
        "# Определяем признаки для кластеризации (все кроме fraud)\n",
        "features = [col for col in df_encoded.columns if col != 'fraud' and col != 'cust_unique_days']\n",
        "data = df_encoded[features]\n",
        "\n",
        "data.columns\n",
        "\n",
        "\"\"\"## 3. Стандартизация данных\"\"\"\n",
        "\n",
        "# Разделяем непрерывные и бинарные признаки\n",
        "continuous_features = ['age', 'amount', 'cust_total_tx', 'cust_unique_merch_total',\n",
        "                      'cust_tx_before', 'cust_unique_merch_before',\n",
        "                      'cust_max_tx_per_day', 'cust_avg_interval', 'cust_avg_tx_per_day_before', 'cust_tx_days_ratio', 'tx_last_7_days']\n",
        "\n",
        "# Все остальные признаки считаем бинарными (one-hot encoded)\n",
        "binary_features = [col for col in features if col not in continuous_features]\n",
        "\n",
        "print(f\"Непрерывные признаки ({len(continuous_features)}): {continuous_features}\")\n",
        "print(f\"Бинарные признаки ({len(binary_features)}): {binary_features[:10]}...\")  # покажем первые 10\n",
        "\n",
        "# Стандартизируем только непрерывные признаки\n",
        "scaled_continuous = (data[continuous_features] - data[continuous_features].mean(axis=0)) / data[continuous_features].std()\n",
        "scaled_continuous = scaled_continuous.fillna(0)\n",
        "\n",
        "# Бинарные признаки оставляем как есть (0/1)\n",
        "scaled_binary = data[binary_features]\n",
        "\n",
        "# Объединяем\n",
        "scaled = pd.concat([scaled_continuous, scaled_binary], axis=1)\n",
        "\n",
        "print(\"\\nДанные после стандартизации:\")\n",
        "print(scaled.head())\n",
        "print(f\"\\nДиапазоны значений:\")\n",
        "print(\"Непрерывные:\", scaled[continuous_features].describe().loc[['min', 'max']].T)\n",
        "print(\"Бинарные: 0 или 1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA3JHeDcm7wG",
        "outputId": "b0c3f6c4-ee1f-4c89-8f1d-4dba4c951c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "from scipy.stats import randint, uniform\n",
        "import joblib\n",
        "\n",
        "class LargeDataBoostingOptimizer:\n",
        "    def __init__(self, n_jobs=-1, random_state=42):\n",
        "        self.n_jobs = n_jobs\n",
        "        self.random_state = random_state\n",
        "        self.best_models = {}\n",
        "        self.results = {}\n",
        "\n",
        "    def create_optimized_models(self):\n",
        "        \"\"\"Создаем модели с оптимизированными параметрами для больших данных\"\"\"\n",
        "\n",
        "        models = {\n",
        "            'AdaBoost': AdaBoostClassifier(\n",
        "                n_estimators=200,  # Увеличиваем для больших данных\n",
        "                learning_rate=0.5,  # Более агрессивное обучение\n",
        "                random_state=self.random_state\n",
        "            ),\n",
        "\n",
        "            'Gradient Boosting': GradientBoostingClassifier(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.05,  # Меньше learning rate для стабильности\n",
        "                max_depth=6,  # Глубже для сложных паттернов\n",
        "                subsample=0.8,  # Субсемплинг для ускорения\n",
        "                max_features='sqrt',  # Уменьшение переобучения\n",
        "                random_state=self.random_state,\n",
        "                validation_fraction=0.1,  # Валидация для ранней остановки\n",
        "                n_iter_no_change=10\n",
        "            ),\n",
        "\n",
        "            'CatBoost': CatBoostClassifier(\n",
        "                iterations=1000,  # Больше итераций\n",
        "                learning_rate=0.05,\n",
        "                depth=8,  # Глубже\n",
        "                l2_leaf_reg=3,  # Регуляризация\n",
        "                random_seed=self.random_state,\n",
        "                verbose=False,\n",
        "                early_stopping_rounds=50,  # Ранняя остановка\n",
        "                thread_count=self.n_jobs,\n",
        "                used_ram_limit='4gb'  # Контроль памяти\n",
        "            ),\n",
        "\n",
        "            'Stochastic Gradient Boosting': HistGradientBoostingClassifier(\n",
        "                max_iter=200,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=8,\n",
        "                min_samples_leaf=20,  # Предотвращение переобучения\n",
        "                l2_regularization=1.0,  # Регуляризация\n",
        "                max_bins=255,  # Для производительности\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                n_iter_no_change=10,\n",
        "                random_state=self.random_state\n",
        "            ),\n",
        "\n",
        "            'XGBoost': xgb.XGBClassifier(\n",
        "                n_estimators=1000,  # Больше деревьев с ранней остановкой\n",
        "                learning_rate=0.05,\n",
        "                max_depth=8,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_alpha=1,  # L1 регуляризация\n",
        "                reg_lambda=1,  # L2 регуляризация\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=self.n_jobs,\n",
        "                tree_method='hist'  # Для больших данных\n",
        "            )\n",
        "        }\n",
        "\n",
        "        return models\n",
        "\n",
        "    def optimize_for_large_data(self, X, y, sample_size=100000):\n",
        "        \"\"\"Быстрая оптимизация на подвыборке\"\"\"\n",
        "        print(f\"Быстрая оптимизация на подвыборке {sample_size} примеров...\")\n",
        "\n",
        "        # Берем подвыборку для быстрой оптимизации\n",
        "        if len(X) > sample_size:\n",
        "            X_sample, _, y_sample, _ = train_test_split(\n",
        "                X, y, train_size=sample_size, random_state=self.random_state, stratify=y\n",
        "            )\n",
        "        else:\n",
        "            X_sample, y_sample = X, y\n",
        "\n",
        "        param_distributions = {\n",
        "            'XGBoost': {\n",
        "                'learning_rate': uniform(0.01, 0.1),\n",
        "                'max_depth': randint(4, 10),\n",
        "                'subsample': uniform(0.7, 0.3),\n",
        "                'colsample_bytree': uniform(0.7, 0.3),\n",
        "                'reg_alpha': uniform(0, 2),\n",
        "                'reg_lambda': uniform(0, 2)\n",
        "            },\n",
        "            'CatBoost': {\n",
        "                'learning_rate': uniform(0.01, 0.1),\n",
        "                'depth': randint(4, 10),\n",
        "                'l2_leaf_reg': uniform(1, 4)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        optimized_params = {}\n",
        "\n",
        "        # Оптимизируем только ключевые модели\n",
        "        for model_name in ['XGBoost', 'CatBoost']:\n",
        "            print(f\"Оптимизация {model_name}...\")\n",
        "\n",
        "            if model_name == 'XGBoost':\n",
        "                model = xgb.XGBClassifier(\n",
        "                    n_estimators=100,\n",
        "                    random_state=self.random_state,\n",
        "                    n_jobs=self.n_jobs,\n",
        "                    tree_method='hist'\n",
        "                )\n",
        "            else:\n",
        "                model = CatBoostClassifier(\n",
        "                    iterations=100,\n",
        "                    random_seed=self.random_state,\n",
        "                    verbose=False,\n",
        "                    thread_count=self.n_jobs\n",
        "                )\n",
        "\n",
        "            search = RandomizedSearchCV(\n",
        "                model,\n",
        "                param_distributions[model_name],\n",
        "                n_iter=10,  # Малое количество итераций для скорости\n",
        "                cv=3,\n",
        "                scoring='f1',\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=1  # Чтобы не перегружать память\n",
        "            )\n",
        "\n",
        "            search.fit(X_sample, y_sample)\n",
        "            optimized_params[model_name] = search.best_params_\n",
        "            print(f\"Лучшие параметры для {model_name}: {search.best_params_}\")\n",
        "\n",
        "        return optimized_params\n",
        "\n",
        "    def train_with_early_stopping(self, X_train, X_val, y_train, y_val, models):\n",
        "        \"\"\"Обучение с ранней остановкой для экономии времени\"\"\"\n",
        "        trained_models = {}\n",
        "\n",
        "        for name, model in models.items():\n",
        "            print(f\"Обучение {name} с ранней остановкой...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            if name == 'CatBoost':\n",
        "                model.fit(\n",
        "                    X_train, y_train,\n",
        "                    eval_set=(X_val, y_val),\n",
        "                    early_stopping_rounds=50,\n",
        "                    verbose=False\n",
        "                )\n",
        "            elif name == 'XGBoost':\n",
        "                model.fit(\n",
        "                    X_train, y_train,\n",
        "                    eval_set=[(X_val, y_val)],\n",
        "                    verbose=False\n",
        "                )\n",
        "            elif name in ['Gradient Boosting', 'Stochastic Gradient Boosting']:\n",
        "                # Эти модели уже имеют встроенную раннюю остановку\n",
        "                model.fit(X_train, y_train)\n",
        "            else:\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "            print(f\"{name} обучен за {training_time:.2f} секунд\")\n",
        "            trained_models[name] = model\n",
        "\n",
        "        return trained_models\n",
        "\n",
        "    def evaluate_model(self, y_true, y_pred, y_pred_proba=None):\n",
        "        metrics = {\n",
        "            'Accuracy': accuracy_score(y_true, y_pred),\n",
        "            'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'F1': f1_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "\n",
        "        if y_pred_proba is not None:\n",
        "            metrics['AUC'] = roc_auc_score(y_true, y_pred_proba)\n",
        "        else:\n",
        "            metrics['AUC'] = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def compare_boosting_methods(self, X, y, test_size=0.2, val_size=0.1):\n",
        "        \"\"\"Основная функция сравнения для больших данных\"\"\"\n",
        "\n",
        "        # Разделяем данные\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        # Дополнительное разделение для валидации (ранняя остановка)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=val_size/(1-test_size),\n",
        "            random_state=self.random_state, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Размеры данных: Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "        # Оптимизация параметров на подвыборке\n",
        "        optimized_params = self.optimize_for_large_data(X_train, y_train)\n",
        "\n",
        "        # Создаем модели\n",
        "        base_models = self.create_optimized_models()\n",
        "\n",
        "        # Применяем оптимизированные параметры\n",
        "        for model_name, params in optimized_params.items():\n",
        "            if model_name == 'XGBoost':\n",
        "                base_models[model_name].set_params(**params)\n",
        "            elif model_name == 'CatBoost':\n",
        "                base_models[model_name].set_params(**params)\n",
        "\n",
        "        # Обучение с ранней остановкой\n",
        "        trained_models = self.train_with_early_stopping(X_train, X_val, y_train, y_val, base_models)\n",
        "\n",
        "        # Оценка на тестовой выборке\n",
        "        results = {}\n",
        "        for name, model in trained_models.items():\n",
        "            print(f\"Оценка {name}...\")\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            else:\n",
        "                y_pred_proba = None\n",
        "\n",
        "            metrics = self.evaluate_model(y_test, y_pred, y_pred_proba)\n",
        "            results[name] = metrics\n",
        "\n",
        "            # Сохраняем лучшие модели\n",
        "            self.best_models[name] = model\n",
        "\n",
        "        self.results = results\n",
        "        return results, trained_models\n",
        "\n",
        "    def print_results(self):\n",
        "        \"\"\"Вывод результатов\"\"\"\n",
        "        results_df = pd.DataFrame(self.results).T\n",
        "        results_df = results_df.round(4)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"СРАВНЕНИЕ МЕТОДОВ БУСТИНГА ДЛЯ БОЛЬШИХ ДАННЫХ\")\n",
        "        print(\"=\"*100)\n",
        "        print(results_df.to_string())\n",
        "\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"ЛУЧШИЕ МОДЕЛИ ПО МЕТРИКАМ:\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        for metric in ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']:\n",
        "            best_model = results_df[metric].idxmax()\n",
        "            best_score = results_df[metric].max()\n",
        "            print(f\"{metric}: {best_model} - {best_score:.4f}\")\n",
        "\n",
        "    def save_best_model(self, model_name, filepath):\n",
        "        \"\"\"Сохранение лучшей модели\"\"\"\n",
        "        if model_name in self.best_models:\n",
        "            joblib.dump(self.best_models[model_name], filepath)\n",
        "            print(f\"Модель {model_name} сохранена в {filepath}\")\n",
        "\n",
        "    def load_and_predict(self, model_path, X_new):\n",
        "        \"\"\"Загрузка модели и предсказание\"\"\"\n",
        "        model = joblib.load(model_path)\n",
        "        return model.predict(X_new)\n",
        "\n",
        "# Пример использования с большими данными\n",
        "def main_large_data():\n",
        "    # Создаем большую синтетическую выборку для демонстрации\n",
        "\n",
        "    X, y = scaled, fraud_labels\n",
        "\n",
        "    # Инициализируем оптимизатор\n",
        "    optimizer = LargeDataBoostingOptimizer(n_jobs=4, random_state=42)\n",
        "\n",
        "    # Сравниваем методы\n",
        "    print(\"Запуск сравнения методов бустинга...\")\n",
        "    results, models = optimizer.compare_boosting_methods(X, y)\n",
        "\n",
        "    # Выводим результаты\n",
        "    optimizer.print_results()\n",
        "\n",
        "    # Анализ производительности\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"РЕКОМЕНДАЦИИ ДЛЯ БОЛЬШИХ ДАННЫХ:\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    results_df = pd.DataFrame(results).T\n",
        "    best_overall = results_df['F1'].idxmax()\n",
        "\n",
        "    print(f\"Рекомендуемая модель: {best_overall}\")\n",
        "    print(\"Причины:\")\n",
        "\n",
        "    if best_overall in ['XGBoost', 'CatBoost']:\n",
        "        print(\"- Оптимизированы для распределенных вычислений\")\n",
        "        print(\"- Эффективное использование памяти\")\n",
        "        print(\"- Встроенные механизмы регуляризации\")\n",
        "    elif best_overall == 'Stochastic Gradient Boosting':\n",
        "        print(\"- Высокая скорость на больших данных\")\n",
        "        print(\"- Хорошая регуляризация\")\n",
        "\n",
        "    # Сохраняем лучшую модель\n",
        "    optimizer.save_best_model(best_overall, f'best_{best_overall}_model.pkl')\n",
        "\n",
        "# # Дополнительная функция для инкрементального обучения\n",
        "# def incremental_learning_example():\n",
        "#     \"\"\"Пример инкрементального обучения для очень больших данных\"\"\"\n",
        "#     from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "#     # Создаем генератор данных (в реальности загружаем пакетами)\n",
        "#     def data_generator(batch_size=50000, total_samples=600000):\n",
        "#         for i in range(0, total_samples, batch_size):\n",
        "#             X_batch, y_batch = make_classification(\n",
        "#                 n_samples=batch_size,\n",
        "#                 n_features=30,\n",
        "#                 random_state=42 + i\n",
        "#             )\n",
        "#             yield X_batch, y_batch\n",
        "\n",
        "#     # Инкрементальное обучение\n",
        "#     model = HistGradientBoostingClassifier(\n",
        "#         max_iter=100,\n",
        "#         learning_rate=0.1,\n",
        "#         early_stopping=False,  # Отключаем для инкрементального обучения\n",
        "#         random_state=42\n",
        "#     )\n",
        "\n",
        "#     print(\"Инкрементальное обучение...\")\n",
        "#     for i, (X_batch, y_batch) in enumerate(data_generator()):\n",
        "#         print(f\"Пакет {i + 1}...\")\n",
        "#         if i == 0:\n",
        "#             model.fit(X_batch, y_batch)\n",
        "#         else:\n",
        "#             # Додобучение на новых данных\n",
        "#             model.set_params(warm_start=True)\n",
        "#             model.fit(X_batch, y_batch)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.datasets import make_classification\n",
        "    main_large_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFR6anURgeCv",
        "outputId": "9631df55-d12a-407b-9d7d-4f697b5555b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запуск сравнения методов бустинга...\n",
            "Размеры данных: Train: (416249, 32), Val: (59465, 32), Test: (118929, 32)\n",
            "Быстрая оптимизация на подвыборке 100000 примеров...\n",
            "Оптимизация XGBoost...\n",
            "Лучшие параметры для XGBoost: {'colsample_bytree': np.float64(0.7093939877366675), 'learning_rate': np.float64(0.09422847745949985), 'max_depth': 7, 'reg_alpha': np.float64(1.8789978831283782), 'reg_lambda': np.float64(1.7896547008552977), 'subsample': np.float64(0.8793699936433255)}\n",
            "Оптимизация CatBoost...\n",
            "Лучшие параметры для CatBoost: {'depth': 6, 'l2_leaf_reg': np.float64(1.0823379771832098), 'learning_rate': np.float64(0.10699098521619943)}\n",
            "Обучение AdaBoost с ранней остановкой...\n",
            "AdaBoost обучен за 99.23 секунд\n",
            "Обучение Gradient Boosting с ранней остановкой...\n",
            "Gradient Boosting обучен за 75.76 секунд\n",
            "Обучение CatBoost с ранней остановкой...\n",
            "CatBoost обучен за 43.49 секунд\n",
            "Обучение Stochastic Gradient Boosting с ранней остановкой...\n",
            "Stochastic Gradient Boosting обучен за 18.51 секунд\n",
            "Обучение XGBoost с ранней остановкой...\n",
            "XGBoost обучен за 73.56 секунд\n",
            "Оценка AdaBoost...\n",
            "Оценка Gradient Boosting...\n",
            "Оценка CatBoost...\n",
            "Оценка Stochastic Gradient Boosting...\n",
            "Оценка XGBoost...\n",
            "\n",
            "====================================================================================================\n",
            "СРАВНЕНИЕ МЕТОДОВ БУСТИНГА ДЛЯ БОЛЬШИХ ДАННЫХ\n",
            "====================================================================================================\n",
            "                              Accuracy  Precision  Recall      F1     AUC\n",
            "AdaBoost                        0.9946     0.8346  0.6938  0.7577  0.9952\n",
            "Gradient Boosting               0.9957     0.8766  0.7549  0.8112  0.9969\n",
            "CatBoost                        0.9962     0.9052  0.7625  0.8277  0.9972\n",
            "Stochastic Gradient Boosting    0.9960     0.8934  0.7569  0.8195  0.9972\n",
            "XGBoost                         0.9960     0.8824  0.7715  0.8233  0.9971\n",
            "\n",
            "====================================================================================================\n",
            "ЛУЧШИЕ МОДЕЛИ ПО МЕТРИКАМ:\n",
            "====================================================================================================\n",
            "Accuracy: CatBoost - 0.9962\n",
            "Precision: CatBoost - 0.9052\n",
            "Recall: XGBoost - 0.7715\n",
            "F1: CatBoost - 0.8277\n",
            "AUC: CatBoost - 0.9972\n",
            "\n",
            "====================================================================================================\n",
            "РЕКОМЕНДАЦИИ ДЛЯ БОЛЬШИХ ДАННЫХ:\n",
            "====================================================================================================\n",
            "Рекомендуемая модель: CatBoost\n",
            "Причины:\n",
            "- Оптимизированы для распределенных вычислений\n",
            "- Эффективное использование памяти\n",
            "- Встроенные механизмы регуляризации\n",
            "Модель CatBoost сохранена в best_CatBoost_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Неудачные попытки"
      ],
      "metadata": {
        "id": "dYRvGIoisE_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ComBoost(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    ComBoost (Комитетный бустинг) - алгоритм построения компактных композиций\n",
        "\n",
        "    Параметры:\n",
        "    -----------\n",
        "    base_estimator : object, default=None\n",
        "        Базовый классификатор\n",
        "    n_estimators : int, default=10\n",
        "        Максимальное количество базовых алгоритмов\n",
        "    l1_ratio : float, default=0.1\n",
        "        Доля объектов, считающихся выбросами (нижняя граница)\n",
        "    l2_ratio : float, default=0.9\n",
        "        Доля объектов для обучения (верхняя граница)\n",
        "    optimize_params : bool, default=True\n",
        "        Оптимизировать ли параметры l1, l2 на каждом шаге\n",
        "    early_stopping_rounds : int, default=5\n",
        "        Количество раундов без улучшения для остановки\n",
        "    random_state : int, default=None\n",
        "        Seed для воспроизводимости\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_estimator=None, n_estimators=10, l1_ratio=0.1,\n",
        "                 l2_ratio=0.9, optimize_params=True, early_stopping_rounds=5,\n",
        "                 random_state=None):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.n_estimators = n_estimators\n",
        "        self.l1_ratio = l1_ratio\n",
        "        self.l2_ratio = l2_ratio\n",
        "        self.optimize_params = optimize_params\n",
        "        self.early_stopping_rounds = early_stopping_rounds\n",
        "        self.random_state = random_state\n",
        "\n",
        "        if self.base_estimator is None:\n",
        "            self.base_estimator = SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Обучение комитетного бустинга\"\"\"\n",
        "        X, y = check_X_y(X, y)\n",
        "        self.classes_ = unique_labels(y)\n",
        "        self.X_, self.y_ = X, y\n",
        "        self.n_samples_, self.n_features_ = X.shape\n",
        "\n",
        "        # Инициализация\n",
        "        self.estimators_ = []  # список базовых алгоритмов\n",
        "        self.margins_history_ = []  # история отступов\n",
        "        self.errors_history_ = []  # история ошибок\n",
        "\n",
        "        # Преобразование меток в {-1, +1}\n",
        "        self.y_binary_ = np.where(y == self.classes_[0], -1, 1)\n",
        "\n",
        "        # Начальные отступы\n",
        "        current_margins = np.zeros(self.n_samples_)\n",
        "\n",
        "        best_error = float('inf')\n",
        "        no_improvement_count = 0\n",
        "\n",
        "        print(\"ComBoost training started...\")\n",
        "\n",
        "        for t in range(self.n_estimators):\n",
        "            # Упорядочивание объектов по возрастанию отступов\n",
        "            sorted_indices = np.argsort(current_margins)\n",
        "\n",
        "            if self.optimize_params:\n",
        "                # Оптимизация параметров l1, l2 на каждом шаге\n",
        "                l1_best, l2_best, error_best = self._optimize_parameters(\n",
        "                    X, self.y_binary_, current_margins, sorted_indices\n",
        "                )\n",
        "            else:\n",
        "                # Фиксированные параметры\n",
        "                l1_best = int(self.l1_ratio * self.n_samples_)\n",
        "                l2_best = int(self.l2_ratio * self.n_samples_)\n",
        "\n",
        "            # Обучение нового базового алгоритма на подвыборке\n",
        "            start_idx = l1_best\n",
        "            end_idx = l2_best\n",
        "\n",
        "            if end_idx <= start_idx:\n",
        "                end_idx = start_idx + 1\n",
        "\n",
        "            train_indices = sorted_indices[start_idx:end_idx]\n",
        "\n",
        "            if len(np.unique(self.y_binary_[train_indices])) < 2:\n",
        "                # Пропускаем если в подвыборке только один класс\n",
        "                continue\n",
        "\n",
        "            estimator = self._clone_estimator()\n",
        "            estimator.fit(X[train_indices], self.y_binary_[train_indices])\n",
        "\n",
        "            # Добавление алгоритма в композицию\n",
        "            self.estimators_.append(estimator)\n",
        "\n",
        "            # Обновление отступов\n",
        "            predictions = estimator.predict(X)\n",
        "            current_margins += predictions\n",
        "            self.margins_history_.append(current_margins.copy())\n",
        "\n",
        "            # Вычисление ошибки\n",
        "            current_error = np.sum(current_margins * self.y_binary_ < 0)\n",
        "            self.errors_history_.append(current_error)\n",
        "\n",
        "            print(f\"Step {t+1}: Error = {current_error}/{self.n_samples_}, \"\n",
        "                  f\"l1={l1_best}, l2={l2_best}, estimators={len(self.estimators_)}\")\n",
        "\n",
        "            # Проверка улучшения\n",
        "            if current_error < best_error:\n",
        "                best_error = current_error\n",
        "                no_improvement_count = 0\n",
        "            else:\n",
        "                no_improvement_count += 1\n",
        "\n",
        "            # Удаление старых алгоритмов (если нужно)\n",
        "            if len(self.estimators_) > 3 and no_improvement_count > 2:\n",
        "                # Удаляем самый старый алгоритм\n",
        "                removed_estimator = self.estimators_.pop(0)\n",
        "                # Пересчитываем отступы\n",
        "                current_margins -= removed_estimator.predict(X)\n",
        "                print(f\"  Removed oldest estimator. Total estimators: {len(self.estimators_)}\")\n",
        "\n",
        "            # Критерий останова\n",
        "            if (no_improvement_count >= self.early_stopping_rounds or\n",
        "                current_error == 0):\n",
        "                break\n",
        "\n",
        "        self.n_estimators_ = len(self.estimators_)\n",
        "        print(f\"Training completed. Final committee size: {self.n_estimators_}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _optimize_parameters(self, X, y, current_margins, sorted_indices):\n",
        "        \"\"\"Оптимизация параметров l1, l2\"\"\"\n",
        "        best_error = float('inf')\n",
        "        best_l1, best_l2 = 0, self.n_samples_\n",
        "\n",
        "        # Поиск по сетке параметров\n",
        "        l1_options = [0, int(0.05 * self.n_samples_), int(0.1 * self.n_samples_)]\n",
        "        l2_options = [int(0.7 * self.n_samples_), int(0.8 * self.n_samples_),\n",
        "                     int(0.9 * self.n_samples_), self.n_samples_]\n",
        "\n",
        "        for l1 in l1_options:\n",
        "            for l2 in l2_options:\n",
        "                if l2 <= l1:\n",
        "                    continue\n",
        "\n",
        "                train_indices = sorted_indices[l1:l2]\n",
        "\n",
        "                if len(np.unique(y[train_indices])) < 2:\n",
        "                    continue\n",
        "\n",
        "                # Быстрое обучение на подвыборке\n",
        "                temp_estimator = self._clone_estimator()\n",
        "                try:\n",
        "                    temp_estimator.fit(X[train_indices], y[train_indices])\n",
        "\n",
        "                    # Оценка качества на всей выборке\n",
        "                    temp_predictions = temp_estimator.predict(X)\n",
        "                    temp_margins = current_margins + temp_predictions\n",
        "                    temp_error = np.sum(temp_margins * y < 0)\n",
        "\n",
        "                    if temp_error < best_error:\n",
        "                        best_error = temp_error\n",
        "                        best_l1, best_l2 = l1, l2\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return best_l1, best_l2, best_error\n",
        "\n",
        "    def _clone_estimator(self):\n",
        "        \"\"\"Создание копии базового классификатора\"\"\"\n",
        "        import copy\n",
        "        return copy.deepcopy(self.base_estimator)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Предсказание классов\"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "\n",
        "        if len(self.estimators_) == 0:\n",
        "            return np.ones(X.shape[0]) * self.classes_[0]\n",
        "\n",
        "        # Голосование комитета\n",
        "        scores = self.decision_function(X)\n",
        "        binary_predictions = np.sign(scores)\n",
        "\n",
        "        # Преобразование обратно в исходные метки\n",
        "        return np.where(binary_predictions == -1, self.classes_[0], self.classes_[1])\n",
        "\n",
        "    def decision_function(self, X):\n",
        "        \"\"\"Функция принятия решений (взвешенная сумма прогнозов)\"\"\"\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "\n",
        "        if len(self.estimators_) == 0:\n",
        "            return np.zeros(X.shape[0])\n",
        "\n",
        "        # Сумма прогнозов всех алгоритмов комитета\n",
        "        scores = np.zeros(X.shape[0])\n",
        "        for estimator in self.estimators_:\n",
        "            try:\n",
        "                predictions = estimator.predict(X)\n",
        "                scores += predictions\n",
        "            except:\n",
        "                # Если predict недоступен, используем predict_proba\n",
        "                probas = estimator.predict_proba(X)\n",
        "                if probas.shape[1] == 2:\n",
        "                    predictions = 2 * probas[:, 1] - 1\n",
        "                else:\n",
        "                    predictions = probas[:, 1] - probas[:, 0]\n",
        "                scores += predictions\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def get_margins(self, X=None, y=None):\n",
        "        \"\"\"Получение отступов для объектов\"\"\"\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        if X is None:\n",
        "            X = self.X_\n",
        "        if y is None:\n",
        "            y = self.y_binary_\n",
        "\n",
        "        scores = self.decision_function(X)\n",
        "        return y * scores\n",
        "\n",
        "    def get_outlier_indices(self, threshold_ratio=0.1):\n",
        "        \"\"\"Получение индексов объектов-выбросов\"\"\"\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        margins = self.get_margins()\n",
        "        n_outliers = int(threshold_ratio * len(margins))\n",
        "\n",
        "        # Выбросы - объекты с наименьшими отступами\n",
        "        outlier_indices = np.argsort(margins)[:n_outliers]\n",
        "        return outlier_indices\n",
        "\n",
        "# Сравнительный класс для экспериментов\n",
        "class ComBoostComparator:\n",
        "    \"\"\"Класс для сравнения ComBoost с другими методами\"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def evaluate_methods(self, X, y, test_size=0.2):\n",
        "        \"\"\"Сравнение различных методов бустинга\"\"\"\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.ensemble import AdaBoostClassifier\n",
        "        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "        # Разделение данных\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        methods = {}\n",
        "        results = {}\n",
        "\n",
        "        # ComBoost с оптимизацией параметров\n",
        "        print(\"=== Training ComBoost with optimization ===\")\n",
        "        comboost_opt = ComBoost(\n",
        "            base_estimator=SVC(kernel='linear', probability=True, random_state=self.random_state),\n",
        "            n_estimators=20,\n",
        "            optimize_params=True,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        comboost_opt.fit(X_train, y_train)\n",
        "        methods['ComBoost_opt'] = comboost_opt\n",
        "\n",
        "        # ComBoost без оптимизации параметров\n",
        "        print(\"\\n=== Training ComBoost without optimization ===\")\n",
        "        comboost_fixed = ComBoost(\n",
        "            base_estimator=SVC(kernel='linear', probability=True, random_state=self.random_state),\n",
        "            n_estimators=20,\n",
        "            optimize_params=False,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        comboost_fixed.fit(X_train, y_train)\n",
        "        methods['ComBoost_fixed'] = comboost_fixed\n",
        "\n",
        "        # AdaBoost для сравнения\n",
        "        print(\"\\n=== Training AdaBoost ===\")\n",
        "        adaboost = AdaBoostClassifier(\n",
        "            estimator=SVC(kernel='linear', probability=True, random_state=self.random_state),\n",
        "            n_estimators=50,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        adaboost.fit(X_train, y_train)\n",
        "        methods['AdaBoost'] = adaboost\n",
        "\n",
        "        # Одиночный SVM для сравнения\n",
        "        print(\"\\n=== Training Single SVM ===\")\n",
        "        single_svm = SVC(kernel='linear', probability=True, random_state=self.random_state)\n",
        "        single_svm.fit(X_train, y_train)\n",
        "        methods['Single_SVM'] = single_svm\n",
        "\n",
        "        # Оценка всех методов\n",
        "        for name, model in methods.items():\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            results[name] = {\n",
        "                'Accuracy': accuracy_score(y_test, y_pred),\n",
        "                'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "                'Recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "                'F1': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "                'N_Estimators': len(model.estimators_) if hasattr(model, 'estimators_') else 1\n",
        "            }\n",
        "\n",
        "            if hasattr(model, 'estimators_'):\n",
        "                print(f\"{name}: {len(model.estimators_)} estimators\")\n",
        "\n",
        "        return results, methods\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.datasets import load_breast_cancer\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    import pandas as pd\n",
        "\n",
        "    # Загрузка данных\n",
        "    X, y = scaled, fraud_labels\n",
        "\n",
        "\n",
        "    # Сравнение методов\n",
        "    print(\"Starting comparison...\")\n",
        "    comparator = ComBoostComparator(random_state=42)\n",
        "    results, models = comparator.evaluate_methods(X, y)\n",
        "\n",
        "    # Вывод результатов\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPARISON RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results_df = pd.DataFrame(results).T\n",
        "    print(results_df.round(4))\n",
        "\n",
        "    # Анализ ComBoost\n",
        "    comboost_model = models['ComBoost_opt']\n",
        "    print(f\"\\nComBoost analysis:\")\n",
        "    print(f\"Final committee size: {comboost_model.n_estimators_}\")\n",
        "    print(f\"Training error progression: {comboost_model.errors_history_}\")\n",
        "\n",
        "    # Выбросы\n",
        "    outliers = comboost_model.get_outlier_indices(threshold_ratio=0.1)\n",
        "    print(f\"Detected outliers (first 10): {outliers[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaNyAvUhtvGY",
        "outputId": "698fc52c-dc0f-44c4-cd2c-e4fd868e7f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting comparison...\n",
            "=== Training ComBoost with optimization ===\n",
            "ComBoost training started...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from typing import List, Tuple, Callable\n",
        "import warnings\n",
        "\n",
        "class BoostingAlgorithm:\n",
        "    def __init__(self, l0: int, l1: int, l2: int, delta_l: int,\n",
        "                 max_iter: int = 10, min_improvement: float = 0.01,\n",
        "                 random_state: int = 42):\n",
        "        \"\"\"\n",
        "        Инициализация алгоритма\n",
        "\n",
        "        Parameters:\n",
        "        l0, l1, l2: параметры отсечения для индексов\n",
        "        delta_l: шаг для перебора k\n",
        "        max_iter: максимальное количество итераций\n",
        "        min_improvement: минимальное улучшение для продолжения алгоритма\n",
        "        random_state: для воспроизводимости\n",
        "        \"\"\"\n",
        "        self.l0 = l0\n",
        "        self.l1 = l1\n",
        "        self.l2 = l2\n",
        "        self.delta_l = delta_l\n",
        "        self.max_iter = max_iter\n",
        "        self.min_improvement = min_improvement\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.base_algorithms = []\n",
        "        self.margins_history = []\n",
        "        self.Q_history = []\n",
        "\n",
        "    def _create_base_algorithms(self):\n",
        "        \"\"\"Создание базовых алгоритмов\"\"\"\n",
        "        return [\n",
        "            ('SVM', SVC(kernel='linear', probability=True, random_state=self.random_state)),\n",
        "            ('DecisionTree', DecisionTreeClassifier(random_state=self.random_state)),\n",
        "            ('LogisticRegression', LogisticRegression(random_state=self.random_state))\n",
        "        ]\n",
        "\n",
        "    def _calculate_margin(self, X: np.ndarray, y: np.ndarray,\n",
        "                         algorithms: List[Tuple[str, object]]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Расчет отступа для объектов\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "        y: метки\n",
        "        algorithms: список базовых алгоритмов\n",
        "\n",
        "        Returns:\n",
        "        margins: отступы для каждого объекта\n",
        "        \"\"\"\n",
        "        margins = np.zeros(len(X))\n",
        "\n",
        "        for name, algo in algorithms:\n",
        "            # Получаем вероятности принадлежности классу +1\n",
        "            if hasattr(algo, 'predict_proba'):\n",
        "                probas = algo.predict_proba(X)\n",
        "                # Берем вероятность класса +1 (второй столбец)\n",
        "                if probas.shape[1] == 2:\n",
        "                    scores = probas[:, 1]\n",
        "                else:\n",
        "                    scores = probas[:, 0]\n",
        "            else:\n",
        "                scores = algo.decision_function(X)\n",
        "\n",
        "            margins += y * scores\n",
        "\n",
        "        return margins\n",
        "\n",
        "    def _calculate_Q(self, margins: np.ndarray) -> int:\n",
        "        \"\"\"\n",
        "        Расчет функционала качества композиции\n",
        "\n",
        "        Parameters:\n",
        "        margins: отступы объектов\n",
        "\n",
        "        Returns:\n",
        "        Q: количество объектов с отступом < 0\n",
        "        \"\"\"\n",
        "        return np.sum(margins < 0)\n",
        "\n",
        "    def _find_best_algorithm(self, X: np.ndarray, y: np.ndarray,\n",
        "                            current_algorithms: List[Tuple[str, object]]) -> Tuple[object, str, float]:\n",
        "        \"\"\"\n",
        "        Поиск лучшего базового алгоритма\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "        y: метки\n",
        "        current_algorithms: текущий список алгоритмов\n",
        "\n",
        "        Returns:\n",
        "        best_algo: лучший алгоритм\n",
        "        best_name: название лучшего алгоритма\n",
        "        best_Q: лучшее значение Q\n",
        "        \"\"\"\n",
        "        base_algos = self._create_base_algorithms()\n",
        "        best_Q = float('inf')\n",
        "        best_algo = None\n",
        "        best_name = None\n",
        "\n",
        "        for name, algo_class in base_algos:\n",
        "            try:\n",
        "                # Обучаем алгоритм\n",
        "                algo = algo_class.fit(X, y)\n",
        "\n",
        "                # Временно добавляем к текущим алгоритмам\n",
        "                temp_algorithms = current_algorithms + [(name, algo)]\n",
        "\n",
        "                # Рассчитываем отступы\n",
        "                margins = self._calculate_margin(X, y, temp_algorithms)\n",
        "\n",
        "                # Рассчитываем Q\n",
        "                Q = self._calculate_Q(margins)\n",
        "\n",
        "                if Q < best_Q:\n",
        "                    best_Q = Q\n",
        "                    best_algo = algo\n",
        "                    best_name = name\n",
        "\n",
        "            except Exception as e:\n",
        "                warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
        "                continue\n",
        "\n",
        "        return best_algo, best_name, best_Q\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray,\n",
        "            sample_size: float = None, stratify: bool = True) -> 'BoostingAlgorithm':\n",
        "        \"\"\"\n",
        "        Обучение алгоритма\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "        y: метки (-1 или +1)\n",
        "        sample_size: доля выборки для уменьшения (None - использовать всю)\n",
        "        stratify: использовать стратификацию при уменьшении выборки\n",
        "\n",
        "        Returns:\n",
        "        self: обученный алгоритм\n",
        "        \"\"\"\n",
        "        # Уменьшение выборки если нужно\n",
        "        if sample_size is not None and sample_size < 1.0:\n",
        "            if stratify:\n",
        "                X, _, y, _ = train_test_split(\n",
        "                    X, y,\n",
        "                    train_size=sample_size,\n",
        "                    stratify=y,\n",
        "                    random_state=self.random_state\n",
        "                )\n",
        "            else:\n",
        "                indices = np.random.choice(\n",
        "                    len(X),\n",
        "                    size=int(len(X) * sample_size),\n",
        "                    replace=False\n",
        "                )\n",
        "                X = X[indices]\n",
        "                y = y[indices]\n",
        "\n",
        "        # Проверка меток\n",
        "        unique_labels = np.unique(y)\n",
        "        if not (set(unique_labels) == {-1, 1} or set(unique_labels) == {0, 1}):\n",
        "            raise ValueError(\"Метки должны быть -1/+1 или 0/1\")\n",
        "\n",
        "        # Преобразование меток 0/1 в -1/+1 если нужно\n",
        "        if set(unique_labels) == {0, 1}:\n",
        "            y = np.where(y == 0, -1, 1)\n",
        "\n",
        "        # Шаг 1: построение первого базового алгоритма\n",
        "        print(\"Шаг 1: Построение первого базового алгоритма\")\n",
        "        best_algo, best_name, best_Q = self._find_best_algorithm(X, y, [])\n",
        "\n",
        "        self.base_algorithms = [(best_name, best_algo)]\n",
        "        current_margins = self._calculate_margin(X, y, self.base_algorithms)\n",
        "\n",
        "        # Сортировка по отступам\n",
        "        sorted_indices = np.argsort(current_margins)\n",
        "        X_sorted = X[sorted_indices]\n",
        "        y_sorted = y[sorted_indices]\n",
        "        margins_sorted = current_margins[sorted_indices]\n",
        "\n",
        "        self.Q_history.append(best_Q)\n",
        "        self.margins_history.append(current_margins.copy())\n",
        "\n",
        "        print(f\"Первый алгоритм: {best_name}, Q = {best_Q}\")\n",
        "\n",
        "        # Основной цикл\n",
        "        for t in range(self.max_iter):\n",
        "            print(f\"\\nИтерация {t + 1}\")\n",
        "\n",
        "            best_iter_algo = None\n",
        "            best_iter_name = None\n",
        "            best_iter_Q = float('inf')\n",
        "            best_k = None\n",
        "\n",
        "            # Вложенный цикл по k\n",
        "            for k in range(self.l1, self.l2 + 1, self.delta_l):\n",
        "                if k <= self.l0 or k >= len(X_sorted):\n",
        "                    continue\n",
        "\n",
        "                # Выбираем подвыборку от l0 до k\n",
        "                sub_indices = range(self.l0, k)\n",
        "                X_sub = X_sorted[sub_indices]\n",
        "                y_sub = y_sorted[sub_indices]\n",
        "\n",
        "                # Строим базовый алгоритм\n",
        "                algo, name, Q = self._find_best_algorithm(X_sub, y_sub, self.base_algorithms)\n",
        "\n",
        "                if Q < best_iter_Q and algo is not None:\n",
        "                    best_iter_Q = Q\n",
        "                    best_iter_algo = algo\n",
        "                    best_iter_name = name\n",
        "                    best_k = k\n",
        "\n",
        "            # Проверяем улучшение\n",
        "            if best_iter_algo is None:\n",
        "                print(\"Не удалось найти подходящий алгоритм на этой итерации\")\n",
        "                break\n",
        "\n",
        "            # Добавляем лучший алгоритм в композицию\n",
        "            self.base_algorithms.append((best_iter_name, best_iter_algo))\n",
        "\n",
        "            # Пересчитываем отступы\n",
        "            current_margins = self._calculate_margin(X, y, self.base_algorithms)\n",
        "\n",
        "            # Сортировка по отступам\n",
        "            sorted_indices = np.argsort(current_margins)\n",
        "            X_sorted = X[sorted_indices]\n",
        "            y_sorted = y[sorted_indices]\n",
        "            margins_sorted = current_margins[sorted_indices]\n",
        "\n",
        "            # Сохраняем историю\n",
        "            self.Q_history.append(best_iter_Q)\n",
        "            self.margins_history.append(current_margins.copy())\n",
        "\n",
        "            print(f\"Добавлен алгоритм: {best_iter_name}, k = {best_k}, Q = {best_iter_Q}\")\n",
        "\n",
        "            # Проверяем условие остановки\n",
        "            if len(self.Q_history) >= 2:\n",
        "                improvement = self.Q_history[-2] - self.Q_history[-1]\n",
        "                if improvement < self.min_improvement:\n",
        "                    print(f\"Улучшение ({improvement}) меньше минимального ({self.min_improvement}), остановка\")\n",
        "                    break\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказание для новых данных\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "\n",
        "        Returns:\n",
        "        predictions: предсказанные метки (-1 или +1)\n",
        "        \"\"\"\n",
        "        if not self.base_algorithms:\n",
        "            raise ValueError(\"Модель не обучена\")\n",
        "\n",
        "        margins = self._calculate_margin(X, np.ones(len(X)), self.base_algorithms)\n",
        "        return np.where(margins >= 0, 1, -1)\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Вероятности принадлежности классу +1\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "\n",
        "        Returns:\n",
        "        probabilities: вероятности класса +1\n",
        "        \"\"\"\n",
        "        if not self.base_algorithms:\n",
        "            raise ValueError(\"Модель не обучена\")\n",
        "\n",
        "        margins = self._calculate_margin(X, np.ones(len(X)), self.base_algorithms)\n",
        "        # Преобразуем отступы в вероятности с помощью сигмоиды\n",
        "        probabilities = 1 / (1 + np.exp(-margins))\n",
        "        return probabilities\n",
        "\n",
        "    def get_algorithm_info(self) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Получение информации об алгоритмах в композиции\n",
        "\n",
        "        Returns:\n",
        "        info: список кортежей (название алгоритма, точность на обучающей выборке)\n",
        "        \"\"\"\n",
        "        info = []\n",
        "        for i, (name, algo) in enumerate(self.base_algorithms):\n",
        "            info.append((f\"{name}_{i}\", name))\n",
        "        return info\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.datasets import make_classification\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    # Генерация тестовых данных\n",
        "    X, y = scaled, fraud_labels\n",
        "\n",
        "    # Преобразование меток в -1/+1\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "\n",
        "    # Разделение на обучающую и тестовую выборки\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Инициализация и обучение алгоритма\n",
        "    booster = BoostingAlgorithm(\n",
        "        l0=6000,      # начальный индекс отсечения\n",
        "        l1=45000,      # начальное значение k\n",
        "        l2=55000,     # конечное значение k\n",
        "        delta_l=2000, # шаг для k\n",
        "        max_iter=10,\n",
        "        min_improvement=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Обучение с уменьшением выборки (80%) и стратификацией\n",
        "    booster.fit(X_train, y_train, sample_size=0.1, stratify=True)\n",
        "\n",
        "    # Предсказание\n",
        "    y_pred = booster.predict(X_test)\n",
        "\n",
        "    # Оценка качества\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Результаты классификации:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Class -1', 'Class +1']))\n",
        "\n",
        "    print(f\"Точность: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Финальное значение Q: {booster.Q_history[-1]}\")\n",
        "    print(f\"Количество алгоритмов в композиции: {len(booster.base_algorithms)}\")\n",
        "\n",
        "    # История значений Q\n",
        "    print(\"\\nИстория значений Q:\")\n",
        "    for i, q in enumerate(booster.Q_history):\n",
        "        print(f\"Итерация {i}: Q = {q}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "rxyBnlSZI0xb",
        "outputId": "d9d9dc7f-5bfa-4556-9fd1-ef7bd253ea35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Шаг 1: Построение первого базового алгоритма\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index([27673, 27663, 27664, 27665, 27666, 27667, 27668, 27669, 27670, 27671,\\n       ...\\n       16150, 26657,  2164, 39428, 11187, 40838, 13616, 16133, 18561, 19935],\\n      dtype='int64', length=41625)] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-824677155.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# Обучение с уменьшением выборки (80%) и стратификацией\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# Предсказание\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-824677155.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_size, stratify)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# Сортировка по отступам\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_margins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mX_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0my_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mmargins_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_margins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([27673, 27663, 27664, 27665, 27666, 27667, 27668, 27669, 27670, 27671,\\n       ...\\n       16150, 26657,  2164, 39428, 11187, 40838, 13616, 16133, 18561, 19935],\\n      dtype='int64', length=41625)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from typing import List, Tuple, Callable\n",
        "import warnings\n",
        "\n",
        "class BoostingAlgorithm:\n",
        "    def __init__(self, l0: int, l1: int, l2: int, delta_l: int,\n",
        "                 max_iter: int = 10, min_improvement: float = 0.01,\n",
        "                 random_state: int = 42):\n",
        "        \"\"\"\n",
        "        Инициализация алгоритма\n",
        "\n",
        "        Parameters:\n",
        "        l0, l1, l2: параметры отсечения для индексов\n",
        "        delta_l: шаг для перебора k\n",
        "        max_iter: максимальное количество итераций\n",
        "        min_improvement: минимальное улучшение для продолжения алгоритма\n",
        "        random_state: для воспроизводимости\n",
        "        \"\"\"\n",
        "        self.l0 = l0\n",
        "        self.l1 = l1\n",
        "        self.l2 = l2\n",
        "        self.delta_l = delta_l\n",
        "        self.max_iter = max_iter\n",
        "        self.min_improvement = min_improvement\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.base_algorithms = []\n",
        "        self.margins_history = []\n",
        "        self.Q_history = []\n",
        "\n",
        "    def _create_base_algorithms(self):\n",
        "        \"\"\"Создание базовых алгоритмов\"\"\"\n",
        "        return [\n",
        "            ('SVM', SVC(kernel='linear', probability=True, random_state=self.random_state)),\n",
        "            ('DecisionTree', DecisionTreeClassifier(random_state=self.random_state, max_depth=3)),\n",
        "            ('LogisticRegression', LogisticRegression(random_state=self.random_state))\n",
        "        ]\n",
        "\n",
        "    def _ensure_numpy(self, X, y):\n",
        "        \"\"\"Преобразование в numpy массивы и сброс индексов\"\"\"\n",
        "        if hasattr(X, 'values'):\n",
        "            X = X.values\n",
        "        if hasattr(y, 'values'):\n",
        "            y = y.values\n",
        "        return X, y\n",
        "\n",
        "    def _calculate_margin(self, X: np.ndarray, y: np.ndarray,\n",
        "                         algorithms: List[Tuple[str, object]]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Расчет отступа для объектов\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "        y: метки\n",
        "        algorithms: список базовых алгоритмов\n",
        "\n",
        "        Returns:\n",
        "        margins: отступы для каждого объекта\n",
        "        \"\"\"\n",
        "        margins = np.zeros(len(X))\n",
        "\n",
        "        for name, algo in algorithms:\n",
        "            try:\n",
        "                # Получаем вероятности принадлежности классу +1\n",
        "                if hasattr(algo, 'predict_proba'):\n",
        "                    probas = algo.predict_proba(X)\n",
        "                    # Берем вероятность класса +1 (второй столбец)\n",
        "                    if probas.shape[1] == 2:\n",
        "                        scores = probas[:, 1]\n",
        "                    else:\n",
        "                        scores = probas[:, 0]\n",
        "                else:\n",
        "                    scores = algo.decision_function(X)\n",
        "\n",
        "                margins += y * scores\n",
        "            except Exception as e:\n",
        "                warnings.warn(f\"Ошибка при расчете отступа для {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return margins\n",
        "\n",
        "    def _calculate_Q(self, margins: np.ndarray) -> int:\n",
        "        \"\"\"\n",
        "        Расчет функционала качества композиции\n",
        "\n",
        "        Parameters:\n",
        "        margins: отступы объектов\n",
        "\n",
        "        Returns:\n",
        "        Q: количество объектов с отступом < 0\n",
        "        \"\"\"\n",
        "        return np.sum(margins < 0)\n",
        "\n",
        "    def _find_best_algorithm(self, X: np.ndarray, y: np.ndarray,\n",
        "                            current_algorithms: List[Tuple[str, object]]) -> Tuple[object, str, float]:\n",
        "        \"\"\"\n",
        "        Поиск лучшего базового алгоритма\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "        y: метки\n",
        "        current_algorithms: текущий список алгоритмов\n",
        "\n",
        "        Returns:\n",
        "        best_algo: лучший алгоритм\n",
        "        best_name: название лучшего алгоритма\n",
        "        best_Q: лучшее значение Q\n",
        "        \"\"\"\n",
        "        base_algos = self._create_base_algorithms()\n",
        "        best_Q = float('inf')\n",
        "        best_algo = None\n",
        "        best_name = None\n",
        "\n",
        "        for name, algo_class in base_algos:\n",
        "            try:\n",
        "                # Обучаем алгоритм\n",
        "                algo = algo_class.fit(X, y)\n",
        "\n",
        "                # Временно добавляем к текущим алгоритмам\n",
        "                temp_algorithms = current_algorithms + [(name, algo)]\n",
        "\n",
        "                # Рассчитываем отступы\n",
        "                margins = self._calculate_margin(X, y, temp_algorithms)\n",
        "\n",
        "                # Рассчитываем Q\n",
        "                Q = self._calculate_Q(margins)\n",
        "\n",
        "                if Q < best_Q:\n",
        "                    best_Q = Q\n",
        "                    best_algo = algo\n",
        "                    best_name = name\n",
        "\n",
        "            except Exception as e:\n",
        "                warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
        "                continue\n",
        "\n",
        "        return best_algo, best_name, best_Q\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray,\n",
        "            sample_size: float = None, stratify: bool = True) -> 'BoostingAlgorithm':\n",
        "        \"\"\"\n",
        "        Обучение алгоритма\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "        y: метки (-1 или +1)\n",
        "        sample_size: доля выборки для уменьшения (None - использовать всю)\n",
        "        stratify: использовать стратификацию при уменьшении выборки\n",
        "\n",
        "        Returns:\n",
        "        self: обученный алгоритм\n",
        "        \"\"\"\n",
        "        # Преобразование в numpy массивы\n",
        "        X, y = self._ensure_numpy(X, y)\n",
        "\n",
        "        # Уменьшение выборки если нужно\n",
        "        if sample_size is not None and sample_size < 1.0:\n",
        "            if stratify:\n",
        "                X, _, y, _ = train_test_split(\n",
        "                    X, y,\n",
        "                    train_size=sample_size,\n",
        "                    stratify=y,\n",
        "                    random_state=self.random_state\n",
        "                )\n",
        "            else:\n",
        "                indices = np.random.choice(\n",
        "                    len(X),\n",
        "                    size=int(len(X) * sample_size),\n",
        "                    replace=False,\n",
        "                    random_state=self.random_state\n",
        "                )\n",
        "                X = X[indices]\n",
        "                y = y[indices]\n",
        "\n",
        "        # Проверка меток\n",
        "        unique_labels = np.unique(y)\n",
        "        if not (set(unique_labels) == {-1, 1} or set(unique_labels) == {0, 1}):\n",
        "            raise ValueError(\"Метки должны быть -1/+1 или 0/1\")\n",
        "\n",
        "        # Преобразование меток 0/1 в -1/+1 если нужно\n",
        "        if set(unique_labels) == {0, 1}:\n",
        "            y = np.where(y == 0, -1, 1)\n",
        "\n",
        "        print(np.count_nonzero(y))\n",
        "        print(np.count_nonzero(y==1))\n",
        "        # Шаг 1: построение первого базового алгоритма\n",
        "        print(\"Шаг 1: Построение первого базового алгоритма\")\n",
        "        best_algo, best_name, best_Q = self._find_best_algorithm(X, y, [])\n",
        "\n",
        "        if best_algo is None:\n",
        "            raise ValueError(\"Не удалось обучить ни один базовый алгоритм\")\n",
        "\n",
        "        self.base_algorithms = [(best_name, best_algo)]\n",
        "        current_margins = self._calculate_margin(X, y, self.base_algorithms)\n",
        "\n",
        "        # Сортировка по отступам\n",
        "        sorted_indices = np.argsort(current_margins)\n",
        "        X_sorted = X[sorted_indices]\n",
        "        y_sorted = y[sorted_indices]\n",
        "        margins_sorted = current_margins[sorted_indices]\n",
        "\n",
        "        self.Q_history.append(best_Q)\n",
        "        self.margins_history.append(current_margins.copy())\n",
        "\n",
        "        print(f\"Первый алгоритм: {best_name}, Q = {best_Q}\")\n",
        "\n",
        "        # Основной цикл\n",
        "        for t in range(self.max_iter):\n",
        "            print(f\"\\nИтерация {t + 1}\")\n",
        "\n",
        "            best_iter_algo = None\n",
        "            best_iter_name = None\n",
        "            best_iter_Q = float('inf')\n",
        "            best_k = None\n",
        "\n",
        "            # Вложенный цикл по k\n",
        "            for k in range(self.l1, self.l2 + 1, self.delta_l):\n",
        "                if k <= self.l0 or k >= len(X_sorted):\n",
        "                    continue\n",
        "\n",
        "                # Выбираем подвыборку от l0 до k\n",
        "                sub_indices = range(self.l0, k)\n",
        "                X_sub = X_sorted[sub_indices]\n",
        "                y_sub = y_sorted[sub_indices]\n",
        "\n",
        "                print(np.count_nonzero(y_sub))\n",
        "                print(np.count_nonzero(y_sub==1))\n",
        "\n",
        "                # Строим базовый алгоритм\n",
        "                algo, name, Q = self._find_best_algorithm(X_sub, y_sub, self.base_algorithms)\n",
        "\n",
        "                if Q < best_iter_Q and algo is not None:\n",
        "                    best_iter_Q = Q\n",
        "                    best_iter_algo = algo\n",
        "                    best_iter_name = name\n",
        "                    best_k = k\n",
        "\n",
        "            # Проверяем улучшение\n",
        "            if best_iter_algo is None:\n",
        "                print(\"Не удалось найти подходящий алгоритм на этой итерации\")\n",
        "                break\n",
        "\n",
        "            # Добавляем лучший алгоритм в композицию\n",
        "            self.base_algorithms.append((best_iter_name, best_iter_algo))\n",
        "\n",
        "            # Пересчитываем отступы\n",
        "            current_margins = self._calculate_margin(X, y, self.base_algorithms)\n",
        "\n",
        "            # Сортировка по отступам\n",
        "            sorted_indices = np.argsort(current_margins)\n",
        "            X_sorted = X[sorted_indices]\n",
        "            y_sorted = y[sorted_indices]\n",
        "            margins_sorted = current_margins[sorted_indices]\n",
        "\n",
        "            # Сохраняем историю\n",
        "            self.Q_history.append(best_iter_Q)\n",
        "            self.margins_history.append(current_margins.copy())\n",
        "\n",
        "            print(f\"Добавлен алгоритм: {best_iter_name}, k = {best_k}, Q = {best_iter_Q}\")\n",
        "\n",
        "            # Проверяем условие остановки\n",
        "            if len(self.Q_history) >= 2:\n",
        "                improvement = self.Q_history[-2] - self.Q_history[-1]\n",
        "                if improvement < self.min_improvement:\n",
        "                    print(f\"Улучшение ({improvement}) меньше минимального ({self.min_improvement}), остановка\")\n",
        "                    break\n",
        "\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказание для новых данных\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "\n",
        "        Returns:\n",
        "        predictions: предсказанные метки (-1 или +1)\n",
        "        \"\"\"\n",
        "        if not self.base_algorithms:\n",
        "            raise ValueError(\"Модель не обучена\")\n",
        "\n",
        "        X, _ = self._ensure_numpy(X, None)\n",
        "        margins = self._calculate_margin(X, np.ones(len(X)), self.base_algorithms)\n",
        "        return np.where(margins >= 0, 1, -1)\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Вероятности принадлежности классу +1\n",
        "\n",
        "        Parameters:\n",
        "        X: признаки\n",
        "\n",
        "        Returns:\n",
        "        probabilities: вероятности класса +1\n",
        "        \"\"\"\n",
        "        if not self.base_algorithms:\n",
        "            raise ValueError(\"Модель не обучена\")\n",
        "\n",
        "        X, _ = self._ensure_numpy(X, None)\n",
        "        margins = self._calculate_margin(X, np.ones(len(X)), self.base_algorithms)\n",
        "        # Преобразуем отступы в вероятности с помощью сигмоиды\n",
        "        probabilities = 1 / (1 + np.exp(-margins))\n",
        "        return probabilities\n",
        "\n",
        "    def get_algorithm_info(self) -> List[Tuple[str, str]]:\n",
        "        \"\"\"\n",
        "        Получение информации об алгоритмах в композиции\n",
        "\n",
        "        Returns:\n",
        "        info: список кортежей (уникальное имя, тип алгоритма)\n",
        "        \"\"\"\n",
        "        info = []\n",
        "        for i, (name, algo) in enumerate(self.base_algorithms):\n",
        "            info.append((f\"{name}_{i}\", name))\n",
        "        return info\n",
        "\n",
        "# Пример использования с исправлениями\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.datasets import make_classification\n",
        "\n",
        "    # Генерация тестовых данных\n",
        "    X, y = scaled,  fraud_labels\n",
        "\n",
        "    # Преобразование меток в -1/+1\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "\n",
        "    # Разделение на обучающую и тестовую выборки\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.05, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Инициализация и обучение алгоритма\n",
        "    booster = BoostingAlgorithm(\n",
        "        l0=0,      # начальный индекс отсечения\n",
        "        l1=45000,      # начальное значение k\n",
        "        l2=55000,     # конечное значение k\n",
        "        delta_l=2000, # шаг для k\n",
        "        max_iter=5,  # уменьшим для теста\n",
        "        min_improvement=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Обучение с уменьшением выборки (10%) и стратификацией\n",
        "        booster.fit(X_train, y_train, sample_size=0.1, stratify=True)\n",
        "\n",
        "        # Предсказание\n",
        "        y_pred = booster.predict(X_test)\n",
        "\n",
        "        # Оценка качества\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Результаты классификации:\")\n",
        "        print(classification_report(y_test, y_pred, target_names=['Class -1', 'Class +1']))\n",
        "\n",
        "        print(f\"Точность: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"Финальное значение Q: {booster.Q_history[-1]}\")\n",
        "        print(f\"Количество алгоритмов в композиции: {len(booster.base_algorithms)}\")\n",
        "\n",
        "        # История значений Q\n",
        "        print(\"\\nИстория значений Q:\")\n",
        "        for i, q in enumerate(booster.Q_history):\n",
        "            print(f\"Итерация {i}: Q = {q}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQse-dDnLG6b",
        "outputId": "e61e2f5b-8a95-4ad4-d7cd-a3dd666e5c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56491\n",
            "684\n",
            "Шаг 1: Построение первого базового алгоритма\n",
            "Первый алгоритм: SVM, Q = 55807\n",
            "\n",
            "Итерация 1\n",
            "45000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавлен алгоритм: DecisionTree, k = 45000, Q = 45000\n",
            "\n",
            "Итерация 2\n",
            "45000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n",
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм SVM вызвал ошибку: The number of classes has to be greater than one; got 1 class\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55000\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-732482010.py:140: UserWarning: Алгоритм LogisticRegression вызвал ошибку: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(-1)\n",
            "  warnings.warn(f\"Алгоритм {name} вызвал ошибку: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавлен алгоритм: DecisionTree, k = 45000, Q = 45000\n",
            "Улучшение (0) меньше минимального (1), остановка\n",
            "\n",
            "==================================================\n",
            "Результаты классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Class -1       0.00      0.00      0.00     29373\n",
            "    Class +1       0.01      1.00      0.02       360\n",
            "\n",
            "    accuracy                           0.01     29733\n",
            "   macro avg       0.01      0.50      0.01     29733\n",
            "weighted avg       0.00      0.01      0.00     29733\n",
            "\n",
            "Точность: 0.0121\n",
            "Финальное значение Q: 45000\n",
            "Количество алгоритмов в композиции: 3\n",
            "\n",
            "История значений Q:\n",
            "Итерация 0: Q = 55807\n",
            "Итерация 1: Q = 45000\n",
            "Итерация 2: Q = 45000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import resample\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "class SVMEnsemble:\n",
        "    def __init__(self,\n",
        "                 T: int = 10,\n",
        "                 l0: int = 0,\n",
        "                 l1: int = 10,\n",
        "                 l2: int = 100,\n",
        "                 delta_l: int = 10,\n",
        "                 min_improvement: float = 0.01,\n",
        "                 max_iter: int = 100,\n",
        "                 svm_params: Optional[dict] = None):\n",
        "        \"\"\"\n",
        "        Инициализация ансамбля SVM\n",
        "\n",
        "        Args:\n",
        "            T: Количество итераций внешнего цикла\n",
        "            l0, l1, l2: параметры отсечения для выбора подвыборки\n",
        "            delta_l: шаг для перебора k\n",
        "            min_improvement: минимальное улучшение Q для продолжения алгоритма\n",
        "            max_iter: максимальное количество итераций основного цикла\n",
        "            svm_params: параметры для SVM\n",
        "        \"\"\"\n",
        "        self.T = T\n",
        "        self.l0 = l0\n",
        "        self.l1 = l1\n",
        "        self.l2 = l2\n",
        "        self.delta_l = delta_l\n",
        "        self.min_improvement = min_improvement\n",
        "        self.max_iter = max_iter\n",
        "        self.svm_params = svm_params or {'kernel': 'linear', 'C': 1.0}\n",
        "\n",
        "        self.base_algorithms = []\n",
        "        self.Q_history = []\n",
        "\n",
        "    def calculate_margin(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Вычисление отступов для всех объектов\n",
        "\n",
        "        Args:\n",
        "            X: матрица признаков\n",
        "            y: метки объектов (-1 или +1)\n",
        "\n",
        "        Returns:\n",
        "            margins: вектор отступов\n",
        "        \"\"\"\n",
        "        margins = np.zeros(len(X))\n",
        "        for svm in self.base_algorithms:\n",
        "            predictions = svm.predict(X)\n",
        "            margins += y * predictions\n",
        "        return margins\n",
        "\n",
        "    def calculate_Q(self, margins: np.ndarray) -> int:\n",
        "        \"\"\"\n",
        "        Вычисление функционала качества Q\n",
        "\n",
        "        Args:\n",
        "            margins: вектор отступов\n",
        "\n",
        "        Returns:\n",
        "            Q: количество объектов с отступом < 0\n",
        "        \"\"\"\n",
        "        return np.sum(margins < 0)\n",
        "\n",
        "    def stratified_reduce_sample(self, X: np.ndarray, y: np.ndarray,\n",
        "                               target_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Стратифицированное уменьшение выборки\n",
        "\n",
        "        Args:\n",
        "            X: исходная матрица признаков\n",
        "            y: исходные метки\n",
        "            target_size: целевой размер выборки\n",
        "\n",
        "        Returns:\n",
        "            X_reduced, y_reduced: уменьшенная выборка\n",
        "        \"\"\"\n",
        "        if target_size >= len(X):\n",
        "            return X.copy(), y.copy()\n",
        "\n",
        "        # Определяем классы\n",
        "        classes = np.unique(y)\n",
        "        n_per_class = target_size // len(classes)\n",
        "\n",
        "        X_reduced_list = []\n",
        "        y_reduced_list = []\n",
        "\n",
        "        for cls in classes:\n",
        "            X_cls = X[y == cls]\n",
        "            y_cls = y[y == cls]\n",
        "\n",
        "            # Выбираем случайную подвыборку для каждого класса\n",
        "            if len(X_cls) > n_per_class:\n",
        "                X_sampled, y_sampled = resample(X_cls, y_cls,\n",
        "                                              n_samples=n_per_class,\n",
        "                                              random_state=42)\n",
        "            else:\n",
        "                X_sampled, y_sampled = X_cls, y_cls\n",
        "\n",
        "            X_reduced_list.append(X_sampled)\n",
        "            y_reduced_list.append(y_sampled)\n",
        "\n",
        "        X_reduced = np.vstack(X_reduced_list)\n",
        "        y_reduced = np.hstack(y_reduced_list)\n",
        "\n",
        "        return X_reduced, y_reduced\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray,\n",
        "           reduce_sample: bool = False, target_size: Optional[int] = None) -> 'SVMEnsemble':\n",
        "        \"\"\"\n",
        "        Обучение ансамбля\n",
        "\n",
        "        Args:\n",
        "            X: матрица признаков\n",
        "            y: метки объектов (-1 или +1)\n",
        "            reduce_sample: флаг стратифицированного уменьшения выборки\n",
        "            target_size: целевой размер уменьшенной выборки\n",
        "\n",
        "        Returns:\n",
        "            self: обученная модель\n",
        "        \"\"\"\n",
        "        # Стратифицированное уменьшение выборки при необходимости\n",
        "        if reduce_sample and target_size is not None:\n",
        "            X, y = self.stratified_reduce_sample(X, y, target_size)\n",
        "\n",
        "        # Инициализация\n",
        "        n_samples = len(X)\n",
        "        margins = np.zeros(n_samples)\n",
        "\n",
        "        # Первый базовый алгоритм\n",
        "        print(\"Строится первый базовый алгоритм...\")\n",
        "        svm1 = SVC(**self.svm_params)\n",
        "        svm1.fit(X, y)\n",
        "        self.base_algorithms.append(svm1)\n",
        "\n",
        "        # Пересчет отступов и сортировка\n",
        "        margins = self.calculate_margin(X, y)\n",
        "        Q_current = self.calculate_Q(margins)\n",
        "        self.Q_history.append(Q_current)\n",
        "\n",
        "        print(f\"Начальный Q: {Q_current}\")\n",
        "\n",
        "        # Основной цикл\n",
        "        iteration = 0\n",
        "        improvement = float('inf')\n",
        "\n",
        "        while improvement > self.min_improvement and iteration < self.max_iter:\n",
        "            iteration += 1\n",
        "            print(f\"\\n--- Итерация {iteration} ---\")\n",
        "\n",
        "            best_svm = None\n",
        "            best_Q = float('inf')\n",
        "            best_margins = None\n",
        "            best_indices = None\n",
        "\n",
        "            # Внешний цикл на T итераций\n",
        "            for t in range(self.T):\n",
        "                print(f\"  Внешняя итерация {t+1}/{self.T}\")\n",
        "\n",
        "                # Сортировка по отступам\n",
        "                sorted_indices = np.argsort(margins)\n",
        "                X_sorted = X[sorted_indices]\n",
        "                y_sorted = y[sorted_indices]\n",
        "\n",
        "                # Внутренний цикл по k\n",
        "                for k in range(self.l1, min(self.l2, n_samples) + 1, self.delta_l):\n",
        "                    # Выбор подвыборки от l0 до k\n",
        "                    start_idx = max(0, self.l0)\n",
        "                    end_idx = min(k, n_samples)\n",
        "\n",
        "                    if end_idx <= start_idx:\n",
        "                        continue\n",
        "\n",
        "                    X_subset = X_sorted[start_idx:end_idx]\n",
        "                    y_subset = y_sorted[start_idx:end_idx]\n",
        "\n",
        "                    # Обучение SVM на подвыборке\n",
        "                    svm_candidate = SVC(**self.svm_params)\n",
        "                    svm_candidate.fit(X_subset, y_subset)\n",
        "\n",
        "                    # Временное добавление кандидата для оценки Q\n",
        "                    temp_algorithms = self.base_algorithms + [svm_candidate]\n",
        "\n",
        "                    # Вычисление отступов с временным алгоритмом\n",
        "                    temp_margins = margins.copy()\n",
        "                    predictions = svm_candidate.predict(X)\n",
        "                    temp_margins += y * predictions\n",
        "\n",
        "                    # Вычисление Q\n",
        "                    Q_candidate = self.calculate_Q(temp_margins)\n",
        "                    best_svm = svm_candidate\n",
        "                    # Проверка на лучший алгоритм\n",
        "                    if Q_candidate < best_Q:\n",
        "                        best_Q = Q_candidate\n",
        "                        best_svm = svm_candidate\n",
        "                        best_margins = temp_margins.copy()\n",
        "                        best_indices = (start_idx, end_idx)\n",
        "\n",
        "            # Добавление лучшего алгоритма в ансамбль\n",
        "            if best_svm is not None:\n",
        "                self.base_algorithms.append(best_svm)\n",
        "                margins = best_margins\n",
        "                Q_previous = Q_current\n",
        "                Q_current = best_Q\n",
        "                improvement = (Q_previous - Q_current) / Q_previous if Q_previous > 0 else 0\n",
        "\n",
        "                self.Q_history.append(Q_current)\n",
        "                print(f\"  Лучший алгоритм: подвыборка [{best_indices[0]}, {best_indices[1]})\")\n",
        "                print(f\"  Q: {Q_current} (улучшение: {improvement:.4f})\")\n",
        "            else:\n",
        "                print(\"  Не найдено подходящего алгоритма\")\n",
        "                break\n",
        "\n",
        "        print(f\"\\nОбучение завершено. Количество базовых алгоритмов: {len(self.base_algorithms)}\")\n",
        "        print(f\"Финальный Q: {Q_current}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказание для новых данных\n",
        "\n",
        "        Args:\n",
        "            X: матрица признаков\n",
        "\n",
        "        Returns:\n",
        "            predictions: предсказанные метки (-1 или +1)\n",
        "        \"\"\"\n",
        "        if not self.base_algorithms:\n",
        "            raise ValueError(\"Модель не обучена\")\n",
        "\n",
        "        margins = np.zeros(len(X))\n",
        "        for svm in self.base_algorithms:\n",
        "            predictions = svm.predict(X)\n",
        "            margins += predictions\n",
        "\n",
        "        return np.sign(margins)\n",
        "\n",
        "    def predict_margins(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Вычисление отступов для новых данных\n",
        "\n",
        "        Args:\n",
        "            X: матрица признаков\n",
        "\n",
        "        Returns:\n",
        "            margins: вектор отступов\n",
        "        \"\"\"\n",
        "        if not self.base_algorithms:\n",
        "            raise ValueError(\"Модель не обучена\")\n",
        "\n",
        "        margins = np.zeros(len(X))\n",
        "        for svm in self.base_algorithms:\n",
        "            predictions = svm.predict(X)\n",
        "            margins += predictions\n",
        "\n",
        "        return margins\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.datasets import make_classification\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    # Генерация тестовых данных\n",
        "    X, y = scaled,  fraud_labels\n",
        "    y = np.where(y == 0, -1, 1)  # Преобразование в метки -1/+1\n",
        "\n",
        "    # Разделение на обучающую и тестовую выборки\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05,\n",
        "                                                        random_state=42, stratify=y)\n",
        "\n",
        "    # Создание и обучение модели\n",
        "    model = SVMEnsemble(\n",
        "        T=5,\n",
        "        l0=200,\n",
        "        l1=40000,\n",
        "        l2=50000,\n",
        "        delta_l=2000,\n",
        "        min_improvement=0.01,\n",
        "        max_iter=10,\n",
        "        svm_params={'kernel': 'linear', 'C': 1.0}\n",
        "    )\n",
        "\n",
        "    # Обучение с стратифицированным уменьшением выборки\n",
        "    model.fit(X_train, y_train, reduce_sample=True, target_size=50000)\n",
        "\n",
        "    # Предсказание\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nТочность на тестовой выборке: {accuracy:.4f}\")\n",
        "\n",
        "    # История изменения Q\n",
        "    print(f\"\\nИстория Q: {model.Q_history}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pw9Lwp2UQpd",
        "outputId": "28d04a3f-54b7-4e73-f0d9-b892eebd866a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Строится первый базовый алгоритм...\n",
            "Начальный Q: 901\n",
            "\n",
            "--- Итерация 1 ---\n",
            "  Внешняя итерация 1/5\n",
            "  Внешняя итерация 2/5\n",
            "  Внешняя итерация 3/5\n",
            "  Внешняя итерация 4/5\n",
            "  Внешняя итерация 5/5\n",
            "  Не найдено подходящего алгоритма\n",
            "\n",
            "Обучение завершено. Количество базовых алгоритмов: 1\n",
            "Финальный Q: 901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but SVC was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Точность на тестовой выборке: 0.9837\n",
            "\n",
            "История Q: [np.int64(901)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from typing import List, Tuple, Optional\n",
        "\n",
        "# def stratified_subsample(X: np.ndarray, y: np.ndarray, frac: float = 1.0, random_state: Optional[int] = None):\n",
        "#     \"\"\"\n",
        "#     Стратифицированное уменьшение выборки.\n",
        "#     Если frac == 1.0 — возвращает исходные данные.\n",
        "#     \"\"\"\n",
        "#     if frac >= 1.0:\n",
        "#         return X, y\n",
        "#     _, X_sub, _, y_sub = train_test_split(\n",
        "#         X, y, test_size=frac, stratify=y, random_state=random_state\n",
        "#     )\n",
        "#     return X_sub, y_sub\n",
        "\n",
        "\n",
        "# def compute_margin(y_true: np.ndarray, predictions: np.ndarray) -> np.ndarray:\n",
        "#     \"\"\"\n",
        "#     Вычисляет отступы: M_i = y_i * sum_b f_b(x_i)\n",
        "#     Здесь predictions: (n_samples, n_base_algos) — результаты всех базовых алгоритмов.\n",
        "#     \"\"\"\n",
        "#     return y_true * np.sum(predictions, axis=1)\n",
        "\n",
        "\n",
        "# def compute_Q(y_true: np.ndarray, predictions: np.ndarray) -> int:\n",
        "#     \"\"\"\n",
        "#     Функционал качества: количество объектов с отступом < 0.\n",
        "#     \"\"\"\n",
        "#     margins = compute_margin(y_true, predictions)\n",
        "#     return np.sum(margins < 0)\n",
        "\n",
        "\n",
        "# def fit_svm(X_train: np.ndarray, y_train: np.ndarray, **svm_kwargs) -> SVC:\n",
        "#     \"\"\"\n",
        "#     Обучает SVM на подвыборке.\n",
        "#     \"\"\"\n",
        "#     clf = SVC(kernel='linear', **svm_kwargs)\n",
        "#     clf.fit(X_train, y_train)\n",
        "#     return clf\n",
        "\n",
        "\n",
        "# def predict_with_ensemble(ensemble: List[SVC], X: np.ndarray) -> np.ndarray:\n",
        "#     \"\"\"\n",
        "#     Возвращает предсказания всех моделей в ансамбле: shape (n_samples, len(ensemble))\n",
        "#     \"\"\"\n",
        "#     if not ensemble:\n",
        "#         return np.zeros((X.shape[0], 0))\n",
        "#     preds = np.column_stack([clf.predict(X) for clf in ensemble])\n",
        "#     return preds\n",
        "\n",
        "\n",
        "# def margin_based_boosting(\n",
        "#     X: np.ndarray,\n",
        "#     y: np.ndarray,\n",
        "#     T: int = 10,\n",
        "#     l0: int = 0,\n",
        "#     l1: int = 10,\n",
        "#     l2: int = 100,\n",
        "#     delta_l: int = 10,\n",
        "#     svm_kwargs: dict = None,\n",
        "#     frac_subsample: float = 1.0,\n",
        "#     random_state: Optional[int] = None,\n",
        "#     min_Q_improvement: float = 1.0,\n",
        "# ) -> List[SVC]:\n",
        "#     \"\"\"\n",
        "#     Реализация описанного margin-based boosting алгоритма.\n",
        "\n",
        "#     Параметры:\n",
        "#     - X, y: обучающая выборка (y ∈ {-1, +1})\n",
        "#     - T: макс. число итераций\n",
        "#     - l0, l1, l2, delta_l: параметры отсечения индексов\n",
        "#     - svm_kwargs: параметры SVM\n",
        "#     - frac_subsample: доля выборки после стратифицированного уменьшения\n",
        "#     - min_Q_improvement: минимальное улучшение Q для продолжения\n",
        "#     \"\"\"\n",
        "#     if svm_kwargs is None:\n",
        "#         svm_kwargs = {}\n",
        "\n",
        "#     # Стратифицированное уменьшение выборки\n",
        "#     X, y = stratified_subsample(X, y, frac=frac_subsample, random_state=random_state)\n",
        "#     n_samples = X.shape[0]\n",
        "\n",
        "#     # Проверка корректности индексов\n",
        "#     l0 = max(0, l0)\n",
        "#     l1 = max(l0 + 1, l1)\n",
        "#     l2 = min(n_samples, l2)\n",
        "#     if l1 >= l2:\n",
        "#         raise ValueError(\"l1 must be < l2 and within dataset size\")\n",
        "\n",
        "#     # Инициализация ансамбля\n",
        "#     ensemble: List[SVC] = []\n",
        "\n",
        "#     # Инициализируем предсказания (пока пусто)\n",
        "#     all_preds = predict_with_ensemble(ensemble, X)  # shape (n, 0)\n",
        "#     margins = compute_margin(y, all_preds)  # все нули на старте\n",
        "#     sorted_indices = np.argsort(margins)\n",
        "\n",
        "#     Q_prev = compute_Q(y, all_preds)\n",
        "#     Q_prev=1000000\n",
        "\n",
        "#     for t in range(T):\n",
        "#         best_clf = None\n",
        "#         best_Q = float('inf')\n",
        "#         best_preds = None\n",
        "\n",
        "#         # Вложенный цикл по k\n",
        "#         for k in range(l1, l2 + 1, delta_l):\n",
        "#             # Подвыборка: от l0 до k (в отсортированной выборке)\n",
        "#             idxs = sorted_indices[l0:k]\n",
        "#             if len(idxs) == 0:\n",
        "#                 continue\n",
        "\n",
        "#             X_sub = X[idxs]\n",
        "#             y_sub = y[idxs]\n",
        "\n",
        "#             # Обучаем SVM\n",
        "#             try:\n",
        "#                 clf = fit_svm(X_sub, y_sub, **svm_kwargs)\n",
        "#             except ValueError:\n",
        "#                 # Пропускаем, если SVM не смог обучиться (например, один класс)\n",
        "#                 continue\n",
        "\n",
        "#             # Добавляем предсказание этой модели ко всем предыдущим\n",
        "#             new_preds = np.column_stack([all_preds, clf.predict(X)]) if ensemble else clf.predict(X).reshape(-1, 1)\n",
        "\n",
        "#             Q_candidate = compute_Q(y, new_preds)\n",
        "\n",
        "#             if Q_candidate < best_Q:\n",
        "#                 best_Q = Q_candidate\n",
        "#                 best_clf = clf\n",
        "#                 best_preds = new_preds\n",
        "\n",
        "#         # Если не нашли лучшего — выходим\n",
        "#         if best_clf is None:\n",
        "#             print(f\"Итерация {t}: не удалось обучить ни один базовый алгоритм. Завершение.\")\n",
        "#             break\n",
        "\n",
        "#         # Добавляем лучший алгоритм в ансамбль\n",
        "#         ensemble.append(best_clf)\n",
        "#         all_preds = best_preds\n",
        "\n",
        "#         # Пересчитываем отступы и сортируем\n",
        "#         margins = compute_margin(y, all_preds)\n",
        "#         sorted_indices = np.argsort(margins)\n",
        "\n",
        "#         # Критерий останова: Q перестал существенно уменьшаться\n",
        "#         Q_curr = best_Q\n",
        "#         # if Q_prev - Q_curr < min_Q_improvement:\n",
        "#         #     print(f\"Итерация {t}: улучшение Q = {Q_prev - Q_curr:.2f} < {min_Q_improvement}. Завершение.\")\n",
        "#         #     break\n",
        "#         Q_prev = Q_curr\n",
        "\n",
        "#         print(f\"Итерация {t+1}/{T}: Q = {Q_curr}\")\n",
        "\n",
        "#     return ensemble\n",
        "\n",
        "\n",
        "# # Пример использования:\n",
        "# if __name__ == \"__main__\":\n",
        "#     from sklearn.datasets import make_classification\n",
        "\n",
        "#     # Генерируем данные с метками ±1\n",
        "#     X, y = scaled.to_numpy(),  fraud_labels.to_numpy()\n",
        "#     y = np.where(y == 0, -1, 1)  # Преобразуем 0/1 → -1/+1\n",
        "\n",
        "#     # Запуск алгоритма\n",
        "#     ensemble = margin_based_boosting(\n",
        "#         X, y,\n",
        "#         T=10,\n",
        "#         l0=50,\n",
        "#         l1=40000,\n",
        "#         l2=50000,\n",
        "#         delta_l=2000,\n",
        "#         frac_subsample=0.1,  # уменьшаем выборку до 10%\n",
        "#         random_state=42,\n",
        "#         min_Q_improvement=1.0\n",
        "#     )\n",
        "\n",
        "#     print(f\"\\nОбучено {len(ensemble)} моделей.\")"
      ],
      "metadata": {
        "id": "gs7731UbY75N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled.to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IIXf6JRadkk",
        "outputId": "252c2213-35d4-42c0-c37e-69bdb58db027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.50433671,  0.95132111, -0.91895216, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 1.50433671, -0.19030159, -0.91895216, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 1.50433671,  0.16417774, -0.91895216, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [-0.75923026,  0.22135761, -1.23379506, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.75923026, -0.10709006, -1.23379506, ...,  1.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.75923026, -0.04425503, -1.23379506, ...,  1.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Комитетный бустинг"
      ],
      "metadata": {
        "id": "HUYWjUo4sVuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from typing import List, Tuple, Optional, Any\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "\n",
        "def stratified_subsample(X: np.ndarray, y: np.ndarray, frac: float = 1.0, random_state: Optional[int] = None):\n",
        "    if frac >= 1.0:\n",
        "        return X, y\n",
        "    _, X_sub, _, y_sub = train_test_split(\n",
        "        X, y, test_size=frac, stratify=y, random_state=random_state\n",
        "    )\n",
        "    return X_sub, y_sub\n",
        "\n",
        "\n",
        "def compute_margin(y_true: np.ndarray, predictions: np.ndarray) -> np.ndarray:\n",
        "    return y_true * np.sum(predictions, axis=1)\n",
        "\n",
        "\n",
        "def compute_Q(y_true: np.ndarray, predictions: np.ndarray) -> int:\n",
        "    margins = compute_margin(y_true, predictions)\n",
        "    return np.sum(margins < 0)\n",
        "\n",
        "\n",
        "def predict_with_ensemble(ensemble: List[Any], X: np.ndarray) -> np.ndarray:\n",
        "    if not ensemble:\n",
        "        return np.zeros((X.shape[0], 0))\n",
        "    preds = np.column_stack([clf.predict(X) for clf in ensemble])\n",
        "    return preds\n",
        "\n",
        "\n",
        "def fit_candidate_models(X_train: np.ndarray, y_train: np.ndarray, random_state: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Обучает три модели: SVM, дерево, лог. регрессия.\n",
        "    Возвращает список (модель, название).\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "\n",
        "    # SVM с линейным ядром\n",
        "    try:\n",
        "        svm = SVC(kernel='linear', random_state=random_state)\n",
        "        svm.fit(X_train, y_train)\n",
        "        candidates.append(svm)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Дерево решений\n",
        "    try:\n",
        "        tree = DecisionTreeClassifier(random_state=random_state, max_depth=10)\n",
        "        tree.fit(X_train, y_train)\n",
        "        candidates.append(tree)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Логистическая регрессия (метки должны быть 0/1 для sklearn, но clf сам преобразует -1/+1)\n",
        "    try:\n",
        "        lr = LogisticRegression(random_state=random_state, max_iter=1000)\n",
        "        lr.fit(X_train, y_train)\n",
        "        candidates.append(lr)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def margin_based_boosting_multimodel(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    T: int = 10,\n",
        "    l0: int = 0,\n",
        "    l1: int = 10,\n",
        "    l2: int = 100,\n",
        "    delta_l: int = 10,\n",
        "    frac_subsample: float = 1.0,\n",
        "    random_state: Optional[int] = None,\n",
        "    min_Q_improvement: float = 1.0,\n",
        ") -> List[Any]:\n",
        "    \"\"\"\n",
        "    Margin-based boosting с выбором лучшей модели из SVM, дерева и лог. регрессии.\n",
        "    \"\"\"\n",
        "    # Стратифицированное уменьшение\n",
        "    X, y = stratified_subsample(X, y, frac=frac_subsample, random_state=random_state)\n",
        "    n_samples = X.shape[0]\n",
        "\n",
        "    l0 = max(0, l0)\n",
        "    l1 = max(l0 + 1, l1)\n",
        "    l2 = min(n_samples, l2)\n",
        "    if l1 >= l2:\n",
        "        raise ValueError(\"l1 must be < l2 and within dataset size\")\n",
        "\n",
        "    ensemble: List[Any] = []\n",
        "    all_preds = predict_with_ensemble(ensemble, X)  # (n, 0)\n",
        "    margins = compute_margin(y, all_preds)\n",
        "    sorted_indices = np.argsort(margins)\n",
        "    Q_prev = compute_Q(y, all_preds)\n",
        "    Q_prev=100000\n",
        "\n",
        "    for t in range(T):\n",
        "        best_candidate = None\n",
        "        best_Q = float('inf')\n",
        "        best_preds = None\n",
        "\n",
        "        # Перебираем k\n",
        "        for k in range(l1, l2 + 1, delta_l):\n",
        "            idxs = sorted_indices[l0:k]\n",
        "            if len(idxs) == 0:\n",
        "                continue\n",
        "\n",
        "            X_sub = X[idxs]\n",
        "            y_sub = y[idxs]\n",
        "\n",
        "            # Обучаем три модели\n",
        "            candidates = fit_candidate_models(X_sub, y_sub, random_state=random_state)\n",
        "\n",
        "            for clf in candidates:\n",
        "                try:\n",
        "                    new_pred = clf.predict(X)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                # Добавляем к текущим предсказаниям\n",
        "                if ensemble:\n",
        "                    candidate_preds = np.column_stack([all_preds, new_pred])\n",
        "                else:\n",
        "                    candidate_preds = new_pred.reshape(-1, 1)\n",
        "\n",
        "                Q_candidate = compute_Q(y, candidate_preds)\n",
        "\n",
        "                if Q_candidate < best_Q:\n",
        "                    best_Q = Q_candidate\n",
        "                    best_candidate = clf\n",
        "                    numforprint=candidates.index(clf)\n",
        "                    best_preds = candidate_preds\n",
        "\n",
        "        if best_candidate is None:\n",
        "            print(f\"Итерация {t}: не удалось обучить ни один кандидат. Завершение.\")\n",
        "            break\n",
        "        if numforprint==0:\n",
        "          print(\"Добавлен базовый алгоритм: SVC\")\n",
        "        elif numforprint==1:\n",
        "          print(\"Добавлен базовый алгоритм: Дерево решений\")\n",
        "        elif numforprint==2:\n",
        "          print(\"Добавлен базовый алгоритм: Логистическая регрессия\")\n",
        "\n",
        "\n",
        "        # Добавляем лучшую модель\n",
        "        ensemble.append(best_candidate)\n",
        "        all_preds = best_preds\n",
        "\n",
        "        # Обновляем отступы и сортировку\n",
        "        margins = compute_margin(y, all_preds)\n",
        "        sorted_indices = np.argsort(margins)\n",
        "\n",
        "\n",
        "        Q_curr = best_Q\n",
        "        print(Q_curr, Q_prev)\n",
        "        if Q_prev - Q_curr < min_Q_improvement:\n",
        "            print(f\"Итерация {t+1}: улучшение Q = {Q_prev - Q_curr:.2f} < {min_Q_improvement}. Завершение.\")\n",
        "            # break\n",
        "        Q_prev = Q_curr\n",
        "\n",
        "        print(f\"Итерация {t+1}/{T}: Q = {Q_curr}\")\n",
        "\n",
        "    return ensemble\n",
        "\n",
        "\n",
        "# Пример использования:\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.datasets import make_classification\n",
        "\n",
        "    X, y = scaled.to_numpy(),  fraud_labels.to_numpy()\n",
        "    y = np.where(y == 0, -1, 1)  # Преобразуем в -1 / +1\n",
        "\n",
        "    ensemble = margin_based_boosting_multimodel(\n",
        "        X, y,\n",
        "        T=10,\n",
        "        l0=50,\n",
        "        l1=40000,\n",
        "        l2=50000,\n",
        "        delta_l=2000,\n",
        "        frac_subsample=0.1,  # уменьшаем выборку до 10%\n",
        "        random_state=42,\n",
        "        min_Q_improvement=1.0\n",
        "    )\n",
        "\n",
        "    print(f\"\\nОбучено {len(ensemble)} моделей.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfcfbGLMwFIK",
        "outputId": "6d9c0eed-70e6-4bd3-f46a-77ae2990aff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавлен базовый алгоритм: Дерево решений\n",
            "137 100000\n",
            "Итерация 1/10: Q = 137\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "93 137\n",
            "Итерация 2/10: Q = 93\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "109 93\n",
            "Итерация 3: улучшение Q = -16.00 < 1.0. Завершение.\n",
            "Итерация 3/10: Q = 109\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "96 109\n",
            "Итерация 4/10: Q = 96\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "102 96\n",
            "Итерация 5: улучшение Q = -6.00 < 1.0. Завершение.\n",
            "Итерация 5/10: Q = 102\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "96 102\n",
            "Итерация 6/10: Q = 96\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "107 96\n",
            "Итерация 7: улучшение Q = -11.00 < 1.0. Завершение.\n",
            "Итерация 7/10: Q = 107\n",
            "Добавлен базовый алгоритм: Логистическая регрессия\n",
            "101 107\n",
            "Итерация 8/10: Q = 101\n",
            "Добавлен базовый алгоритм: Дерево решений\n",
            "107 101\n",
            "Итерация 9: улучшение Q = -6.00 < 1.0. Завершение.\n",
            "Итерация 9/10: Q = 107\n",
            "Добавлен базовый алгоритм: Логистическая регрессия\n",
            "100 107\n",
            "Итерация 10/10: Q = 100\n",
            "\n",
            "Обучено 10 моделей.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Данные (замените на свои при необходимости)\n",
        "# -------------------------------\n",
        "X, y = scaled.to_numpy(),  fraud_labels.to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Модели\n",
        "# -------------------------------\n",
        "models = {\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Обучение и получение предсказаний НА ТЕСТОВОЙ ВЫБОРКЕ\n",
        "# -------------------------------\n",
        "test_predictions = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    test_predictions[name] = model.predict(X_test)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Оценка p как доля ошибок на тестовой выборке\n",
        "# -------------------------------\n",
        "errors = {}\n",
        "for name, y_pred in test_predictions.items():\n",
        "    num_errors = np.sum(y_pred != y_test)\n",
        "    p = num_errors / len(y_test)\n",
        "    errors[name] = p\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Расчёт весов: w = ln((1 - p) / p)\n",
        "# -------------------------------\n",
        "weights = {}\n",
        "eps = 1e-10  # защита от деления на 0 и log(0)\n",
        "for name, p in errors.items():\n",
        "    p = np.clip(p, eps, 1 - eps)\n",
        "    w = np.log((1 - p) / p)\n",
        "    weights[name] = w\n",
        "\n",
        "print(\"Вероятности ошибки (p):\")\n",
        "for name, p in errors.items():\n",
        "    print(f\"{name}: {p:.4f}\")\n",
        "\n",
        "print(\"\\nВеса моделей:\")\n",
        "for name, w in weights.items():\n",
        "    print(f\"{name}: {w:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Построение композиции на тестовой выборке\n",
        "# -------------------------------\n",
        "weighted_sum = np.zeros(len(X_test))\n",
        "for name in models.keys():\n",
        "    preds = test_predictions[name]\n",
        "    # Преобразуем метки в -1 / +1 для корректного взвешивания\n",
        "    votes = np.where(preds == 1, 1, -1)\n",
        "    weighted_sum += weights[name] * votes\n",
        "\n",
        "y_pred_composite = (weighted_sum > 0).astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Сравнение метрик\n",
        "# -------------------------------\n",
        "results = {}\n",
        "\n",
        "# Метрики базовых моделей\n",
        "for name, y_pred in test_predictions.items():\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Метрика композиции\n",
        "results['Composite'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_composite),\n",
        "    'Precision': precision_score(y_test, y_pred_composite),\n",
        "    'Recall': recall_score(y_test, y_pred_composite),\n",
        "    'F1': f1_score(y_test, y_pred_composite)\n",
        "}\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Вывод\n",
        "# -------------------------------\n",
        "df_results = pd.DataFrame(results).T\n",
        "print(\"\\nСравнение моделей (метрики на тестовой выборке):\")\n",
        "print(df_results.round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C4UARSly5zD",
        "outputId": "fcd26a75-b545-43e9-d87f-784102c44037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вероятности ошибки (p):\n",
            "SVM: 0.0045\n",
            "DecisionTree: 0.0068\n",
            "LogisticRegression: 0.0046\n",
            "\n",
            "Веса моделей:\n",
            "SVM: 5.4052\n",
            "DecisionTree: 4.9849\n",
            "LogisticRegression: 5.3803\n",
            "\n",
            "Сравнение моделей (метрики на тестовой выборке):\n",
            "                    Accuracy  Precision  Recall      F1\n",
            "SVM                   0.9955     0.9068  0.7028  0.7919\n",
            "DecisionTree          0.9932     0.7090  0.7444  0.7263\n",
            "LogisticRegression    0.9954     0.8933  0.7056  0.7884\n",
            "Composite             0.9955     0.8963  0.7120  0.7936\n"
          ]
        }
      ]
    }
  ]
}